{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlatnNO9_PqC"
      },
      "outputs": [],
      "source": [
        "#columnas_seleccionadas = [\n",
        "   # 'action_taken2', 'purchaser_type', 'preapproval',\n",
        "    #'loan_type', 'loan_purpose', 'lien_status','reverse_mortgage','open_end_line_of_credit', 'business_or_commercial_purpose' 'loan_amount', 'hoepa_status',\n",
        "    #'occupancy_type', 'applicant_credit_score_type','combined_loan_to_value_ratio', 'property_value ','occupancy_type ','manufactured_home_secured_proper',\n",
        "    #'applicant_age', 'hoepa_status ', 'loan_term ','manufactured_home_land_property', 'multifamily_affordable_units','income ','applicant_credit_score_type'\n",
        "    #'conforming_loan_limit', 'derived_loan_product_type', 'applicant_sex '"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CARGA INFORMACION"
      ],
      "metadata": {
        "id": "sdOJT4aYW57H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U4QUPjqqMoT",
        "outputId": "809009f2-8187-4743-c6e1-5de40c1a6b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOtPJP40qXVi"
      },
      "outputs": [],
      "source": [
        "#Librerias\n",
        "import os\n",
        "from pandas import read_csv\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#graficas\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQYOmU4zqab7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reemplaza la ruta con la ubicaci√≥n de tu archivo Stata (.dta)\n",
        "file_path = \"/content/drive/MyDrive/Proyecto Grado/HDMA/Version Final/LAR_18_19_Muestra.dta\"\n",
        "\n",
        "# Cargar el archivo Stata en un DataFrame\n",
        "data = pd.read_stata(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6ouoPFVHGh-",
        "outputId": "a3ff3814-d3e6-4f61-e0de-7ec25a4b651a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 61 columns):\n",
            " #   Column                            Non-Null Count    Dtype   \n",
            "---  ------                            --------------    -----   \n",
            " 0   activity_year                     1000000 non-null  int16   \n",
            " 1   lei                               1000000 non-null  object  \n",
            " 2   state_code                        1000000 non-null  object  \n",
            " 3   county_code                       1000000 non-null  object  \n",
            " 4   action_taken                      1000000 non-null  category\n",
            " 5   purchaser_type                    1000000 non-null  category\n",
            " 6   preapproval                       1000000 non-null  int8    \n",
            " 7   loan_type                         1000000 non-null  category\n",
            " 8   loan_purpose                      1000000 non-null  category\n",
            " 9   lien_status                       1000000 non-null  int8    \n",
            " 10  reverse_mortgage                  973978 non-null   float64 \n",
            " 11  open_end_line_of_credit           974190 non-null   float64 \n",
            " 12  business_or_commercial_purpose    974161 non-null   float64 \n",
            " 13  loan_amount                       1000000 non-null  int32   \n",
            " 14  combined_loan_to_value_ratio      701585 non-null   float64 \n",
            " 15  interest_rate                     628255 non-null   float64 \n",
            " 16  rate_spread                       537791 non-null   float64 \n",
            " 17  hoepa_status                      1000000 non-null  category\n",
            " 18  total_loan_costs                  489783 non-null   float64 \n",
            " 19  total_points_and_fees             5839 non-null     float64 \n",
            " 20  origination_charges               490672 non-null   float64 \n",
            " 21  discount_points                   170575 non-null   float64 \n",
            " 22  lender_credits                    196770 non-null   float64 \n",
            " 23  loan_term                         961136 non-null   float64 \n",
            " 24  prepayment_penalty_term           46380 non-null    float64 \n",
            " 25  intro_rate_period                 164157 non-null   float64 \n",
            " 26  negative_amortization             973747 non-null   float64 \n",
            " 27  interest_only_payment             973747 non-null   float64 \n",
            " 28  balloon_payment                   973747 non-null   float64 \n",
            " 29  other_nonamortizing_features      973747 non-null   float64 \n",
            " 30  property_value                    782201 non-null   float64 \n",
            " 31  construction_method               1000000 non-null  category\n",
            " 32  occupancy_type                    1000000 non-null  category\n",
            " 33  manufactured_home_secured_proper  1000000 non-null  category\n",
            " 34  manufactured_home_land_property_  1000000 non-null  category\n",
            " 35  multifamily_affordable_units      212 non-null      float64 \n",
            " 36  income                            957551 non-null   float64 \n",
            " 37  applicant_credit_score_type       1000000 non-null  category\n",
            " 38  applicant_ethnicity_1             999646 non-null   category\n",
            " 39  applicant_race_1                  1000000 non-null  category\n",
            " 40  applicant_sex                     1000000 non-null  category\n",
            " 41  submission_of_application         974115 non-null   category\n",
            " 42  initially_payable_to_institution  974115 non-null   category\n",
            " 43  denial_reason_1                   1000000 non-null  category\n",
            " 44  denial_reason_2                   39487 non-null    category\n",
            " 45  denial_reason_3                   6998 non-null     category\n",
            " 46  denial_reason_4                   652 non-null      category\n",
            " 47  applicant_age                     1000000 non-null  category\n",
            " 48  applicant_age_above_62            992442 non-null   float64 \n",
            " 49  total_units                       1000000 non-null  category\n",
            " 50  debt_to_income_ratio              336026 non-null   category\n",
            " 51  conforming_loan_limit             1000000 non-null  category\n",
            " 52  derived_loan_product_type         1000000 non-null  category\n",
            " 53  derived_dwelling_category         1000000 non-null  category\n",
            " 54  action_taken2                     1000000 non-null  category\n",
            " 55  protegido_edad                    1000000 non-null  int8    \n",
            " 56  no_protegido_edad                 1000000 non-null  int8    \n",
            " 57  protegido_mujer                   1000000 non-null  int8    \n",
            " 58  no_protegido_hombre               1000000 non-null  int8    \n",
            " 59  protegido_raza                    1000000 non-null  int8    \n",
            " 60  no_protegido_raza                 1000000 non-null  int8    \n",
            "dtypes: category(26), float64(22), int16(1), int32(1), int8(8), object(3)\n",
            "memory usage: 228.9+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Informaci√≥n sobre tipos de datos y valores nulos\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93R_7LZyKVHx",
        "outputId": "0dc54532-3d2e-4110-f7f3-13b9d85ec554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categor√≠as √∫nicas en applicant_sex : ['mujer', 'hombre', 'selecciono ambas opciones']\n",
            "Categories (3, object): ['hombre' < 'mujer' < 'selecciono ambas opciones']\n",
            "Categor√≠as √∫nicas en applicant_race_1: ['negro/afroamericano', 'blanco', 'sin info', 'asiatico', 'nativo americano/alaska', ..., 'koreano', 'guameno o chamorro', 'japones', 'samoan', 'hawaiano']\n",
            "Length: 18\n",
            "Categories (18, object): ['nativo americano/alaska' < 'asiatico' < 'negro/afroamericano' <\n",
            "                          'hawaiano/isleno del pacifico' ... 'hawaiano' < 'guameno o chamorro' < 'samoan' <\n",
            "                          'otro isleno del pacifico']\n",
            "Categor√≠as √∫nicas en applicant_ethnicity_1: ['no hispano/latino', 'hispano/latino', 'sin info', 'mexicano', 'otro hispano/latino', 'cubano', 'puertorriqueno', NaN, 'no aplica']\n",
            "Categories (8, object): ['hispano/latino' < 'no hispano/latino' < 'sin info' < 'no aplica' < 'mexicano' <\n",
            "                         'puertorriqueno' < 'cubano' < 'otro hispano/latino']\n",
            "Categor√≠as √∫nicas en applicant_age_above_62: [ 0.  1. nan]\n"
          ]
        }
      ],
      "source": [
        "categorias_columna1 = data['applicant_sex'].unique()\n",
        "categorias_columna2 = data['applicant_race_1'].unique()\n",
        "categorias_columna3 = data['applicant_ethnicity_1'].unique()\n",
        "categorias_columna4 = data['applicant_age_above_62'].unique()\n",
        "\n",
        "print(\"Categor√≠as √∫nicas en applicant_sex :\", categorias_columna1)\n",
        "print(\"Categor√≠as √∫nicas en applicant_race_1:\", categorias_columna2)\n",
        "print(\"Categor√≠as √∫nicas en applicant_ethnicity_1:\", categorias_columna3)\n",
        "print(\"Categor√≠as √∫nicas en applicant_age_above_62:\", categorias_columna4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nn5FPcOSnhP",
        "outputId": "e18f40f1-a03b-4947-9186-10ffcc36fa29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                negado\n",
            "1              aprobado\n",
            "2              aprobado\n",
            "3              aprobado\n",
            "4         no finalizado\n",
            "              ...      \n",
            "999995         aprobado\n",
            "999996         aprobado\n",
            "999997         aprobado\n",
            "999998         aprobado\n",
            "999999         aprobado\n",
            "Name: action_taken2, Length: 1000000, dtype: category\n",
            "Categories (3, object): ['aprobado' < 'negado' < 'no finalizado']\n"
          ]
        }
      ],
      "source": [
        "# Mostrar los datos originales de una columna espec√≠fica\n",
        "columna_original = data['action_taken2']\n",
        "print(columna_original)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPARACION DATA SET PARA FASE MODELOS"
      ],
      "metadata": {
        "id": "N0kZeYIFXDcX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEbPOdckxAcE"
      },
      "source": [
        "Se abordan los siguientes pasos:\n",
        "\n",
        "Preparar el conjunto de datos\n",
        "Dividir en el entrenamiento y la prueba\n",
        "Transformar/Codificar las etiquetas de las variables\n",
        "PExplorar diferents modelos de clasificacion\n",
        "Compara el desempe√±o de todos los modelos.\n",
        "Seleccionar un  modelo ganador y ajuste los hiperpar√°metros para obtener una mayor precisi√≥n.\n",
        "Evaluaci√≥n detallada de resultado con una matriz de confusi√≥n y diferentes medidas.\n",
        "Caracter√≠sticas m√°s importantes para predecir la calificaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPWORLm2VlwU"
      },
      "outputs": [],
      "source": [
        "# Eliminaci√≥n de variables que tengan valores nulos\n",
        "#df1 = data.dropna(axis=1)\n",
        "\n",
        "# Eliminaci√≥n de tres columnas adicionales espec√≠ficas\n",
        "columnas_adicionales = ['lei', 'state_code', 'county_code', 'activity_year']\n",
        "#df1 = df1.drop(columnas_adicionales, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTvxB8laR2Bt",
        "outputId": "d4328529-cef2-4a12-9aa8-666d2d68ee4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correspondencia de clases original para 'action_taken2':\n",
            "{'negado': 'negado', 'aprobado': 'aprobado', 'no finalizado': 'no finalizado'}\n"
          ]
        }
      ],
      "source": [
        "# Guardar la correspondencia de clases para 'action_taken2'\n",
        "correspondencia_original_action_taken2 = dict(zip(data['action_taken2'].unique(), data['action_taken2'].unique()))\n",
        "print(\"Correspondencia de clases original para 'action_taken2':\")\n",
        "print(correspondencia_original_action_taken2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir valores de action_taken2 a min√∫sculas\n",
        "data['action_taken2'] = data['action_taken2'].str.lower()\n",
        "\n",
        "# Mapeo de los valores de action_taken2 a los valores correspondientes en action_taken3\n",
        "mapping = {\n",
        "    'aprobado': 'Otorgado',\n",
        "    'negado': 'No Otorgado',\n",
        "    'no finalizado': 'No Otorgado'\n",
        "}\n",
        "\n",
        "# Crear la nueva columna action_taken3 basada en los valores de action_taken2\n",
        "data['action_taken3'] = data['action_taken2'].replace(mapping)"
      ],
      "metadata": {
        "id": "wmLFFlSzOHYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los datos originales de una columna espec√≠fica\n",
        "columna_original = data['action_taken3']\n",
        "print(columna_original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1zttyxScggr",
        "outputId": "9a308df5-09a8-4798-d41a-8491d1b886b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         No Otorgado\n",
            "1            Otorgado\n",
            "2            Otorgado\n",
            "3            Otorgado\n",
            "4         No Otorgado\n",
            "             ...     \n",
            "999995       Otorgado\n",
            "999996       Otorgado\n",
            "999997       Otorgado\n",
            "999998       Otorgado\n",
            "999999       Otorgado\n",
            "Name: action_taken3, Length: 1000000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir valores a cadenas y guardar los originales en nuevas columnas\n",
        "columns_to_check = ['protegido_edad', 'no_protegido_edad', 'protegido_mujer', 'no_protegido_hombre', 'protegido_raza', 'no_protegido_raza']\n",
        "\n",
        "for column in columns_to_check:\n",
        "    # Crear una nueva columna con el nombre original + '_antes_conversion'\n",
        "    data[column + '_antes_conversion'] = data[column]\n",
        "    # Convertir los valores a num√©ricos\n",
        "    data[column] = pd.to_numeric(data[column], errors='coerce')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Crear la nueva columna 'poblacion_protegida' basada en las condiciones\n",
        "data['poblacion_protegida'] = np.where(\n",
        "    (data['protegido_edad'] == 1) |\n",
        "    (data['protegido_mujer'] == 1) |\n",
        "    (data['protegido_raza'] == 1),\n",
        "    1,  # Si alguna de las condiciones se cumple, asigna 1\n",
        "    np.where(\n",
        "        (data['no_protegido_edad'] == 1) |\n",
        "        (data['no_protegido_hombre'] == 1) |\n",
        "        (data['no_protegido_raza'] == 1),\n",
        "        0,  # Si alguna de las condiciones se cumple, asigna 0\n",
        "        np.nan  # Si ninguna de las condiciones se cumple, asigna NaN por defecto\n",
        "    )\n",
        ")\n",
        "\n",
        "# Crear una nueva columna 'poblacion_protegida_nueva' basada en las condiciones\n",
        "data['poblacion_protegida_nueva'] = np.where(\n",
        "    (data['protegido_edad'] == 1) |\n",
        "    (data['protegido_mujer'] == 1) |\n",
        "    (data['protegido_raza'] == 1),\n",
        "    1,  # Si alguna de las condiciones se cumple, asigna 1\n",
        "    np.where(\n",
        "        (data['no_protegido_edad'] == 1) |\n",
        "        (data['no_protegido_hombre'] == 1) |\n",
        "        (data['no_protegido_raza'] == 1),\n",
        "        0,  # Si alguna de las condiciones se cumple, asigna 0\n",
        "        np.nan  # Si ninguna de las condiciones se cumple, asigna NaN por defecto\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "5xF1y1AQOJ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informaci√≥n sobre tipos de datos y valores nulos\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7dHvaIWYrCH",
        "outputId": "07f6178c-6c29-43a5-cfd7-c4132ced66bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 70 columns):\n",
            " #   Column                                Non-Null Count    Dtype   \n",
            "---  ------                                --------------    -----   \n",
            " 0   activity_year                         1000000 non-null  int16   \n",
            " 1   lei                                   1000000 non-null  object  \n",
            " 2   state_code                            1000000 non-null  object  \n",
            " 3   county_code                           1000000 non-null  object  \n",
            " 4   action_taken                          1000000 non-null  category\n",
            " 5   purchaser_type                        1000000 non-null  category\n",
            " 6   preapproval                           1000000 non-null  int8    \n",
            " 7   loan_type                             1000000 non-null  category\n",
            " 8   loan_purpose                          1000000 non-null  category\n",
            " 9   lien_status                           1000000 non-null  int8    \n",
            " 10  reverse_mortgage                      973978 non-null   float64 \n",
            " 11  open_end_line_of_credit               974190 non-null   float64 \n",
            " 12  business_or_commercial_purpose        974161 non-null   float64 \n",
            " 13  loan_amount                           1000000 non-null  int32   \n",
            " 14  combined_loan_to_value_ratio          701585 non-null   float64 \n",
            " 15  interest_rate                         628255 non-null   float64 \n",
            " 16  rate_spread                           537791 non-null   float64 \n",
            " 17  hoepa_status                          1000000 non-null  category\n",
            " 18  total_loan_costs                      489783 non-null   float64 \n",
            " 19  total_points_and_fees                 5839 non-null     float64 \n",
            " 20  origination_charges                   490672 non-null   float64 \n",
            " 21  discount_points                       170575 non-null   float64 \n",
            " 22  lender_credits                        196770 non-null   float64 \n",
            " 23  loan_term                             961136 non-null   float64 \n",
            " 24  prepayment_penalty_term               46380 non-null    float64 \n",
            " 25  intro_rate_period                     164157 non-null   float64 \n",
            " 26  negative_amortization                 973747 non-null   float64 \n",
            " 27  interest_only_payment                 973747 non-null   float64 \n",
            " 28  balloon_payment                       973747 non-null   float64 \n",
            " 29  other_nonamortizing_features          973747 non-null   float64 \n",
            " 30  property_value                        782201 non-null   float64 \n",
            " 31  construction_method                   1000000 non-null  category\n",
            " 32  occupancy_type                        1000000 non-null  category\n",
            " 33  manufactured_home_secured_proper      1000000 non-null  category\n",
            " 34  manufactured_home_land_property_      1000000 non-null  category\n",
            " 35  multifamily_affordable_units          212 non-null      float64 \n",
            " 36  income                                957551 non-null   float64 \n",
            " 37  applicant_credit_score_type           1000000 non-null  category\n",
            " 38  applicant_ethnicity_1                 999646 non-null   category\n",
            " 39  applicant_race_1                      1000000 non-null  category\n",
            " 40  applicant_sex                         1000000 non-null  category\n",
            " 41  submission_of_application             974115 non-null   category\n",
            " 42  initially_payable_to_institution      974115 non-null   category\n",
            " 43  denial_reason_1                       1000000 non-null  category\n",
            " 44  denial_reason_2                       39487 non-null    category\n",
            " 45  denial_reason_3                       6998 non-null     category\n",
            " 46  denial_reason_4                       652 non-null      category\n",
            " 47  applicant_age                         1000000 non-null  category\n",
            " 48  applicant_age_above_62                992442 non-null   float64 \n",
            " 49  total_units                           1000000 non-null  category\n",
            " 50  debt_to_income_ratio                  336026 non-null   category\n",
            " 51  conforming_loan_limit                 1000000 non-null  category\n",
            " 52  derived_loan_product_type             1000000 non-null  category\n",
            " 53  derived_dwelling_category             1000000 non-null  category\n",
            " 54  action_taken2                         1000000 non-null  object  \n",
            " 55  protegido_edad                        1000000 non-null  int8    \n",
            " 56  no_protegido_edad                     1000000 non-null  int8    \n",
            " 57  protegido_mujer                       1000000 non-null  int8    \n",
            " 58  no_protegido_hombre                   1000000 non-null  int8    \n",
            " 59  protegido_raza                        1000000 non-null  int8    \n",
            " 60  no_protegido_raza                     1000000 non-null  int8    \n",
            " 61  action_taken3                         1000000 non-null  object  \n",
            " 62  protegido_edad_antes_conversion       1000000 non-null  int8    \n",
            " 63  no_protegido_edad_antes_conversion    1000000 non-null  int8    \n",
            " 64  protegido_mujer_antes_conversion      1000000 non-null  int8    \n",
            " 65  no_protegido_hombre_antes_conversion  1000000 non-null  int8    \n",
            " 66  protegido_raza_antes_conversion       1000000 non-null  int8    \n",
            " 67  no_protegido_raza_antes_conversion    1000000 non-null  int8    \n",
            " 68  poblacion_protegida                   1000000 non-null  float64 \n",
            " 69  poblacion_protegida_nueva             1000000 non-null  float64 \n",
            "dtypes: category(25), float64(24), int16(1), int32(1), int8(14), object(5)\n",
            "memory usage: 264.2+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREACION DE DATA SET PARA MODELOS"
      ],
      "metadata": {
        "id": "8PNN3qH9XhFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo DataFrame con solo las columnas seleccionadas\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "# Lista de columnas seleccionadas\n",
        "columnas_seleccionadas = ['action_taken3', 'income', 'applicant_sex', 'loan_amount', 'loan_purpose', 'loan_type', 'debt_to_income_ratio','combined_loan_to_value_ratio', 'applicant_age']\n",
        "df = data[columnas_seleccionadas].copy()\n",
        "\n",
        "\n",
        "# Usar LabelEncoder para transformar la columna 'action_taken2'\n",
        "\n",
        "label_encoder_action_taken3 = LabelEncoder()\n",
        "df['action_taken3'] = label_encoder_action_taken3.fit_transform(df['action_taken3'])\n",
        "\n",
        "# Convertir variables categ√≥ricas a num√©ricas y mapear clases de 'action_taken2' a n√∫meros\n",
        "label_encoder = LabelEncoder()\n",
        "#df['purchaser_type'] = label_encoder.fit_transform(df['purchaser_type'])\n",
        "#df['preapproval'] = label_encoder.fit_transform(df['preapproval'])\n",
        "df['loan_type'] = label_encoder.fit_transform(df['loan_type'])\n",
        "df['loan_purpose'] = label_encoder.fit_transform(df['loan_purpose'])\n",
        "#df['lien_status'] = label_encoder.fit_transform(df['lien_status'])\n",
        "#f['hoepa_status'] = label_encoder.fit_transform(df['hoepa_status'])\n",
        "#df['occupancy_type'] = label_encoder.fit_transform(df['occupancy_type'])\n",
        "#df['applicant_credit_score_type'] = label_encoder.fit_transform(df['applicant_credit_score_type'])\n",
        "#df['manufactured_home_land_property_'] = label_encoder.fit_transform(df['manufactured_home_land_property_'])\n",
        "df['applicant_sex'] = label_encoder.fit_transform(df['applicant_sex'])\n",
        "#df['conforming_loan_limit'] = label_encoder.fit_transform(df['conforming_loan_limit'])\n",
        "#df['derived_loan_product_type'] = label_encoder.fit_transform(df['derived_loan_product_type'])\n",
        "#df['applicant_race_1'] = label_encoder.fit_transform(df['applicant_race_1'])\n",
        "#df['applicant_ethnicity_1'] = label_encoder.fit_transform(df['applicant_ethnicity_1'])\n",
        "df['debt_to_income_ratio'] = label_encoder.fit_transform(df['debt_to_income_ratio'])\n",
        "df['applicant_age'] = label_encoder.fit_transform(df['applicant_age'])\n",
        "\n",
        "# Definir la funci√≥n para mapear 'action_taken2' a 'aprobado'\n",
        "def map_approval(action_taken3):\n",
        "    # Define aqu√≠ tus criterios para determinar si un pr√©stamo fue aprobado o no\n",
        "    # Por ejemplo, si action_taken es 1, considera que el pr√©stamo fue aprobado (1); de lo contrario, no aprobado (0)\n",
        "    if action_taken3 == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Aplicar la funci√≥n para crear la columna 'aprobado'\n",
        "#df['otorgado'] = df['action_taken3'].apply(map_approval)\n",
        "\n",
        "# Dividir el conjunto de datos en caracter√≠sticas (X) y etiquetas (y)\n",
        "#X = df.drop(['otorgado', 'action_taken3'], axis=1)  # Excluir 'aprobado' y 'action_taken2' de las caracter√≠sticas\n",
        "#y = df['otorgado']  # Usar 'aprobado' como variable de respuesta\n",
        "\n",
        "# Dividir el conjunto de datos en caracter√≠sticas (X) y etiquetas (y)\n",
        "X = df.drop(['action_taken3'], axis=1)  # Excluir 'action_taken3' de las caracter√≠sticas\n",
        "y = df['action_taken3']  # Usar 'action_taken3' como variable de respuesta\n",
        "\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Resto del c√≥digo...\n",
        "# Definir las transformaciones para las variables num√©ricas y categ√≥ricas\n",
        "numeric_features = ['loan_amount',\n",
        "                    'income','combined_loan_to_value_ratio']\n",
        "categorical_features = ['applicant_sex','loan_purpose', 'loan_type','debt_to_income_ratio','applicant_age']\n",
        "\n",
        "# Crear el transformador para datos num√©ricos\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Imputaci√≥n de valores faltantes con la media\n",
        "    ('scaler', StandardScaler())  # Estandarizaci√≥n de las variables\n",
        "])\n",
        "\n",
        "# Crear el transformador para datos categ√≥ricos\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputaci√≥n de valores faltantes con la moda\n",
        "    ('encoder', OneHotEncoder(drop='first'))  # Codificaci√≥n one-hot\n",
        "])\n",
        "\n",
        "# Combinar transformadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "t-970em3gjHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informaci√≥n sobre tipos de datos y valores nulos\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OgJw-XYYmiI",
        "outputId": "be1b0c27-ea91-41eb-d823-5766013b89d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                        Non-Null Count    Dtype  \n",
            "---  ------                        --------------    -----  \n",
            " 0   action_taken3                 1000000 non-null  int64  \n",
            " 1   income                        957551 non-null   float64\n",
            " 2   applicant_sex                 1000000 non-null  int64  \n",
            " 3   loan_amount                   1000000 non-null  int32  \n",
            " 4   loan_purpose                  1000000 non-null  int64  \n",
            " 5   loan_type                     1000000 non-null  int64  \n",
            " 6   debt_to_income_ratio          1000000 non-null  int64  \n",
            " 7   combined_loan_to_value_ratio  701585 non-null   float64\n",
            " 8   applicant_age                 1000000 non-null  int64  \n",
            "dtypes: float64(2), int32(1), int64(6)\n",
            "memory usage: 64.8 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENTRENAMIENTO MODELOS"
      ],
      "metadata": {
        "id": "eFM4qx-SXoa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lGBM Model"
      ],
      "metadata": {
        "id": "2VLnJUuZX69b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIELCkYEye5b",
        "outputId": "cb140273-b87a-4623-86b8-d49074d96c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054874 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "LGBMClassifier Accuracy: 0.807315\n",
            "LGBMClassifier Confusion Matrix:\n",
            "[[ 47588  21468]\n",
            " [ 17069 113875]]\n",
            "LGBMClassifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.69      0.71     69056\n",
            "           1       0.84      0.87      0.86    130944\n",
            "\n",
            "    accuracy                           0.81    200000\n",
            "   macro avg       0.79      0.78      0.78    200000\n",
            "weighted avg       0.80      0.81      0.81    200000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Instanciar y entrenar el modelo LGBMClassifier\n",
        "lgbm_model = LGBMClassifier()\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_lgbm = lgbm_model.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "conf_matrix_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
        "classification_rep_lgbm = classification_report(y_test, y_pred_lgbm)\n",
        "\n",
        "# Imprimir m√©tricas de rendimiento para LGBMClassifier\n",
        "print(f'LGBMClassifier Accuracy: {accuracy_lgbm}')\n",
        "print(f'LGBMClassifier Confusion Matrix:\\n{conf_matrix_lgbm}')\n",
        "print(f'LGBMClassifier Classification Report:\\n{classification_rep_lgbm}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVD8cW8bRFTs"
      },
      "source": [
        "Precisi√≥n, recall y F1 GTB Mejor modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxyWtl5148aN",
        "outputId": "d7fbb3c7-f6db-4142-89ce-63f3e93ff6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " No Aprobado       0.74      0.69      0.71     69056\n",
            "    Aprobado       0.84      0.87      0.86    130944\n",
            "\n",
            "    accuracy                           0.81    200000\n",
            "   macro avg       0.79      0.78      0.78    200000\n",
            "weighted avg       0.80      0.81      0.81    200000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_lgbm, target_names=['No Aprobado', 'Aprobado']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUACION DESEMPE√ëO EN GRUPOS DE INTER√âS"
      ],
      "metadata": {
        "id": "fGUvGPNmYTXU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zDC28N2rU7",
        "outputId": "acd8f803-bb1e-4b50-bb53-e65723172dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©tricas de desempe√±o para el grupo protegido_edad:\n",
            "Accuracy: 0.8090\n",
            "Precision: 0.8080\n",
            "Recall: 0.8090\n",
            "F1 Score: 0.8076\n",
            "\n",
            "M√©tricas de desempe√±o para el grupo no_protegido_edad:\n",
            "Accuracy: 0.8131\n",
            "Precision: 0.8098\n",
            "Recall: 0.8131\n",
            "F1 Score: 0.8105\n",
            "\n",
            "M√©tricas de desempe√±o para el grupo protegido_sexo:\n",
            "Accuracy: 0.8135\n",
            "Precision: 0.8113\n",
            "Recall: 0.8135\n",
            "F1 Score: 0.8116\n",
            "\n",
            "M√©tricas de desempe√±o para el grupo no_protegido_sexo:\n",
            "Accuracy: 0.8122\n",
            "Precision: 0.8089\n",
            "Recall: 0.8122\n",
            "F1 Score: 0.8094\n",
            "\n",
            "M√©tricas de desempe√±o para el grupo protegido_raza:\n",
            "Accuracy: 0.8118\n",
            "Precision: 0.8112\n",
            "Recall: 0.8118\n",
            "F1 Score: 0.8111\n",
            "\n",
            "M√©tricas de desempe√±o para el grupo no_protegido_raza:\n",
            "Accuracy: 0.8133\n",
            "Precision: 0.8094\n",
            "Recall: 0.8133\n",
            "F1 Score: 0.8102\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Codificar la variable objetivo 'action_taken2'\n",
        "label_encoder_action_taken3 = LabelEncoder()\n",
        "data['action_taken3_encoded'] = label_encoder_action_taken3.fit_transform(data['action_taken3'])\n",
        "\n",
        "# Funci√≥n para filtrar los datos seg√∫n el grupo de inter√©s\n",
        "def filtrar_datos_para_grupo(grupo, data):\n",
        "    if grupo == 'protegido_edad':\n",
        "        return data[data['applicant_age_above_62'] == 1]\n",
        "    elif grupo == 'no_protegido_edad':\n",
        "        return data[data['applicant_age_above_62'] == 0]\n",
        "    elif grupo == 'protegido_sexo':\n",
        "        return data[data['applicant_sex'] != 'hombre']\n",
        "    elif grupo == 'no_protegido_sexo':\n",
        "        return data[data['applicant_sex'] == 'hombre']\n",
        "    elif grupo == 'protegido_raza':\n",
        "        return data[data['applicant_race_1'] != 'blanco']\n",
        "    elif grupo == 'no_protegido_raza':\n",
        "        return data[data['applicant_race_1'] == 'blanco']\n",
        "    else:\n",
        "        raise ValueError(\"Grupo de inter√©s no v√°lido\")\n",
        "\n",
        "# Definir los grupos de inter√©s\n",
        "grupos_interes = ['protegido_edad', 'no_protegido_edad', 'protegido_sexo', 'no_protegido_sexo', 'protegido_raza', 'no_protegido_raza']\n",
        "\n",
        "# Definir las caracter√≠sticas num√©ricas y categ√≥ricas\n",
        "numeric_features = ['loan_amount',\n",
        "                    'income','combined_loan_to_value_ratio']\n",
        "categorical_features = ['applicant_race_1', 'applicant_sex','loan_purpose', 'loan_type','applicant_age','debt_to_income_ratio']\n",
        "\n",
        "\n",
        "# Crear transformadores para datos num√©ricos y categ√≥ricos\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "# Combinar transformadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Entrenar el modelo XGBoost\n",
        "lgbm_model1 = XGBClassifier(objective='multi:softmax', num_class=3, random_state=0)\n",
        "\n",
        "# Ciclo para calcular y mostrar las m√©tricas de desempe√±o para cada grupo\n",
        "for grupo in grupos_interes:\n",
        "    # Filtrar los datos para el grupo actual\n",
        "    df_grupo = filtrar_datos_para_grupo(grupo, data)\n",
        "\n",
        "    # Separar caracter√≠sticas y etiquetas\n",
        "    X_grupo = df_grupo.drop(['action_taken3', 'action_taken3_encoded'], axis=1)\n",
        "    y_grupo = df_grupo['action_taken3_encoded']\n",
        "\n",
        "    # Preprocesar datos\n",
        "    X_grupo_preprocessed = preprocessor.fit_transform(X_grupo)\n",
        "\n",
        "    # Entrenar el modelo en el grupo actual\n",
        "    lgbm_model1.fit(X_grupo_preprocessed, y_grupo)\n",
        "\n",
        "    # Predecir utilizando el modelo\n",
        "    y_pred_grupo = lgbm_model1.predict(X_grupo_preprocessed)\n",
        "\n",
        "    # Calcular y mostrar las m√©tricas de desempe√±o\n",
        "    accuracy = accuracy_score(y_grupo, y_pred_grupo)\n",
        "    precision = precision_score(y_grupo, y_pred_grupo, average='weighted')\n",
        "    recall = recall_score(y_grupo, y_pred_grupo, average='weighted')\n",
        "    f1 = f1_score(y_grupo, y_pred_grupo, average='weighted')\n",
        "\n",
        "    print(f'M√©tricas de desempe√±o para el grupo {grupo}:')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "    print(f'F1 Score: {f1:.4f}')\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksdOlqao5XkZ",
        "outputId": "e6ace119-3d5b-450b-a10b-b7b13ba947ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grupo: protegido_edad\n",
            "N√∫mero de observaciones: 186660\n",
            "\n",
            "Grupo: no_protegido_edad\n",
            "N√∫mero de observaciones: 805782\n",
            "\n",
            "Grupo: protegido_sexo\n",
            "N√∫mero de observaciones: 331899\n",
            "\n",
            "Grupo: no_protegido_sexo\n",
            "N√∫mero de observaciones: 668101\n",
            "\n",
            "Grupo: protegido_raza\n",
            "N√∫mero de observaciones: 230854\n",
            "\n",
            "Grupo: no_protegido_raza\n",
            "N√∫mero de observaciones: 769146\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Contar el n√∫mero de observaciones en cada grupo filtrado\n",
        "for grupo in grupos_interes:\n",
        "    df_grupo = filtrar_datos_para_grupo(grupo, data)\n",
        "    print(f\"Grupo: {grupo}\")\n",
        "    print(f\"N√∫mero de observaciones: {len(df_grupo)}\")  # Contar el n√∫mero de filas del DataFrame filtrado\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METRICAS DE FAIRNESS"
      ],
      "metadata": {
        "id": "tQeP2FcHNmvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Parity Difference\n",
        "\n",
        "Corresponde a la diferencia entre la probabilidad de pertenecer a la clase positiva dado que se pertenece a la clase protegida y la posibilidad de pertenecer a la clase positiva dado que se pertenece a la clase no protegida\n",
        "\n",
        "Disparate Impact"
      ],
      "metadata": {
        "id": "OH1wQeP2O8Q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METRICAS DE EQUIDAD POR GENERO"
      ],
      "metadata": {
        "id": "YxAo_Uan_bGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = data['applicant_sex'].value_counts()\n",
        "print(value_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTxYy9nCw4Tp",
        "outputId": "c92e9fd9-a6dd-494b-957a-1d7b88a5e925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applicant_sex\n",
            "hombre                       668101\n",
            "mujer                        330947\n",
            "selecciono ambas opciones       952\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = df['applicant_sex'].value_counts()\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqazyBjq9LjX",
        "outputId": "1e2613f6-aa91-44fe-efc8-98e4edae9e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applicant_sex\n",
            "0    668101\n",
            "1    330947\n",
            "2       952\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = data['applicant_age'].value_counts()\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utMVxLUeGN_W",
        "outputId": "cac4c006-f010-455a-8d5e-697e6ceccf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applicant_age\n",
            "35-44       233298\n",
            "45-54       218875\n",
            "25-34       193393\n",
            "55-64       175896\n",
            "65-74       104118\n",
            ">74          37531\n",
            "<25          29331\n",
            "sin info      7558\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = df['applicant_age'].value_counts()\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS1kQ6PSGDUN",
        "outputId": "b4c6ab61-65bf-4848-f98c-b9e500f46e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applicant_age\n",
            "1    233298\n",
            "2    218875\n",
            "0    193393\n",
            "3    175896\n",
            "4    104118\n",
            "6     37531\n",
            "5     29331\n",
            "7      7558\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informaci√≥n sobre tipos de datos y valores nulos\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFx0BpOjv3Zz",
        "outputId": "8bd9ef1d-259d-41ee-95c5-6e99b22fa049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                        Non-Null Count    Dtype  \n",
            "---  ------                        --------------    -----  \n",
            " 0   action_taken3                 1000000 non-null  int64  \n",
            " 1   income                        957551 non-null   float64\n",
            " 2   applicant_sex                 1000000 non-null  int64  \n",
            " 3   loan_amount                   1000000 non-null  int32  \n",
            " 4   loan_purpose                  1000000 non-null  int64  \n",
            " 5   loan_type                     1000000 non-null  int64  \n",
            " 6   debt_to_income_ratio          1000000 non-null  int64  \n",
            " 7   combined_loan_to_value_ratio  701585 non-null   float64\n",
            " 8   applicant_age                 1000000 non-null  int64  \n",
            "dtypes: float64(2), int32(1), int64(6)\n",
            "memory usage: 64.8 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Hacer una copia del DataFrame df y llamarlo df1\n",
        "df1 = df.copy()\n",
        "\n",
        "# Informaci√≥n sobre tipos de datos y valores nulos en df1\n",
        "print(df1.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bomj-At9xG2-",
        "outputId": "60387ce7-5dbb-4bba-86af-dff3d54edc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                        Non-Null Count    Dtype  \n",
            "---  ------                        --------------    -----  \n",
            " 0   action_taken3                 1000000 non-null  int64  \n",
            " 1   income                        957551 non-null   float64\n",
            " 2   applicant_sex                 1000000 non-null  int64  \n",
            " 3   loan_amount                   1000000 non-null  int32  \n",
            " 4   loan_purpose                  1000000 non-null  int64  \n",
            " 5   loan_type                     1000000 non-null  int64  \n",
            " 6   debt_to_income_ratio          1000000 non-null  int64  \n",
            " 7   combined_loan_to_value_ratio  701585 non-null   float64\n",
            " 8   applicant_age                 1000000 non-null  int64  \n",
            "dtypes: float64(2), int32(1), int64(6)\n",
            "memory usage: 64.8 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicciones = lgbm_model.predict(df.drop('action_taken3', axis=1))\n"
      ],
      "metadata": {
        "id": "2nkraZvTu0lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(df['action_taken3'], predicciones))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eREeLJdS46GA",
        "outputId": "b71bfeb2-93c5-4928-e8a6-a1c7c367cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.69      0.71    345686\n",
            "           1       0.84      0.87      0.85    654314\n",
            "\n",
            "    accuracy                           0.81   1000000\n",
            "   macro avg       0.79      0.78      0.78   1000000\n",
            "weighted avg       0.80      0.81      0.81   1000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPARACION ACCURARY -PRECISION -RECALL calculadas para los grupos masculino y femenino"
      ],
      "metadata": {
        "id": "POXR6nrN_-Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def calcular_metricas_por_grupo(y_true, y_pred, grupo):\n",
        "    if grupo == 0:  # Masculino\n",
        "        indices_grupo = np.where(df['applicant_sex'] == 0)[0]\n",
        "    elif grupo == 1:  # Femenino\n",
        "        indices_grupo = np.where(df['applicant_sex'].isin([1, 2]))[0]\n",
        "    else:\n",
        "        raise ValueError(\"El valor de grupo debe ser 0 (masculino) o 1 (femenino)\")\n",
        "\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "\n",
        "    precision = precision_score(y_true_grupo, y_pred_grupo)\n",
        "    recall = recall_score(y_true_grupo, y_pred_grupo)\n",
        "    f1 = f1_score(y_true_grupo, y_pred_grupo)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "precision_masculino, recall_masculino, f1_masculino = calcular_metricas_por_grupo(df['action_taken3'], predicciones, 0)\n",
        "precision_femenino, recall_femenino, f1_femenino = calcular_metricas_por_grupo(df['action_taken3'], predicciones, 1)\n",
        "\n",
        "print(\"M√©tricas para el grupo masculino:\")\n",
        "print(\"Precisi√≥n:\", precision_masculino)\n",
        "print(\"Recall:\", recall_masculino)\n",
        "print(\"F1-score:\", f1_masculino)\n",
        "\n",
        "print(\"\\nM√©tricas para el grupo femenino:\")\n",
        "print(\"Precisi√≥n:\", precision_femenino)\n",
        "print(\"Recall:\", recall_femenino)\n",
        "print(\"F1-score:\", f1_femenino)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBxuUY2FU23J",
        "outputId": "d98d4621-c2e9-427c-a040-89d93665e531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©tricas para el grupo masculino:\n",
            "Precisi√≥n: 0.8441716795799898\n",
            "Recall: 0.869139063875906\n",
            "F1-score: 0.8564734519329075\n",
            "\n",
            "M√©tricas para el grupo femenino:\n",
            "Precisi√≥n: 0.8347540356897423\n",
            "Recall: 0.8675363251097321\n",
            "F1-score: 0.8508295237631364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Graficar las precisiones por grupo\n",
        "plt.bar(['Masculino', 'Femenino'], [precision_masculino, precision_femenino])\n",
        "plt.xlabel('Grupo')\n",
        "plt.ylabel('Precisi√≥n')\n",
        "plt.title('Precisi√≥n por grupo de g√©nero')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "L4i7bCjp5DLC",
        "outputId": "63a93aab-311e-40d0-9a53-e680c53dd323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calcular_proporcion_aprobacion(y_true, y_pred, grupo):\n",
        "    if grupo == 0:  # Masculino\n",
        "        indices_grupo = np.where(df['applicant_sex'] == 0)[0]\n",
        "    elif grupo == 1:  # Femenino\n",
        "        indices_grupo = np.where(df['applicant_sex'].isin([1, 2]))[0]\n",
        "    else:\n",
        "        raise ValueError(\"El valor de grupo debe ser 0 (masculino) o 1 (femenino)\")\n",
        "\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    aprobados = np.sum(y_pred_grupo == 1)\n",
        "    proporcion_aprobacion = aprobados / len(y_pred_grupo)\n",
        "    return proporcion_aprobacion\n",
        "\n",
        "def calcular_fpr(y_true, y_pred, grupo):\n",
        "    if grupo == 0:  # Masculino\n",
        "        indices_grupo = np.where(df['applicant_sex'] == 0)[0]\n",
        "    elif grupo == 1:  # Femenino\n",
        "        indices_grupo = np.where(df['applicant_sex'].isin([1, 2]))[0]\n",
        "    else:\n",
        "        raise ValueError(\"El valor de grupo debe ser 0 (masculino) o 1 (femenino)\")\n",
        "\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    falsos_positivos = np.sum((y_true_grupo == 0) & (y_pred_grupo == 1))\n",
        "    negativos_reales = np.sum(y_true_grupo == 0)\n",
        "    fpr = falsos_positivos / negativos_reales\n",
        "    return fpr\n",
        "\n",
        "def calcular_fnr(y_true, y_pred, grupo):\n",
        "    if grupo == 0:  # Masculino\n",
        "        indices_grupo = np.where(df['applicant_sex'] == 0)[0]\n",
        "    elif grupo == 1:  # Femenino\n",
        "        indices_grupo = np.where(df['applicant_sex'].isin([1, 2]))[0]\n",
        "    else:\n",
        "        raise ValueError(\"El valor de grupo debe ser 0 (masculino) o 1 (femenino)\")\n",
        "\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    falsos_negativos = np.sum((y_true_grupo == 1) & (y_pred_grupo == 0))\n",
        "    positivos_reales = np.sum(y_true_grupo == 1)\n",
        "    fnr = falsos_negativos / positivos_reales\n",
        "    return fnr\n",
        "\n",
        "def calcular_diferencia_aprobacion(y_true, y_pred):\n",
        "    proporcion_aprobacion_masculino = calcular_proporcion_aprobacion(y_true, y_pred, 0)\n",
        "    proporcion_aprobacion_femenino = calcular_proporcion_aprobacion(y_true, y_pred, 1)\n",
        "    diferencia_aprobacion = np.abs(proporcion_aprobacion_masculino - proporcion_aprobacion_femenino)\n",
        "    return diferencia_aprobacion\n",
        "\n",
        "def calcular_diferencia_fpr(y_true, y_pred):\n",
        "    fpr_masculino = calcular_fpr(y_true, y_pred, 0)\n",
        "    fpr_femenino = calcular_fpr(y_true, y_pred, 1)\n",
        "    diferencia_fpr = np.abs(fpr_masculino - fpr_femenino)\n",
        "    return diferencia_fpr\n",
        "\n",
        "def calcular_diferencia_fnr(y_true, y_pred):\n",
        "    fnr_masculino = calcular_fnr(y_true, y_pred, 0)\n",
        "    fnr_femenino = calcular_fnr(y_true, y_pred, 1)\n",
        "    diferencia_fnr = np.abs(fnr_masculino - fnr_femenino)\n",
        "    return diferencia_fnr\n",
        "\n",
        "# Calcular m√©tricas\n",
        "diferencia_aprobacion = calcular_diferencia_aprobacion(df['action_taken3'], predicciones)\n",
        "diferencia_fpr = calcular_diferencia_fpr(df['action_taken3'], predicciones)\n",
        "diferencia_fnr = calcular_diferencia_fnr(df['action_taken3'], predicciones)\n",
        "\n",
        "print(\"Diferencia en tasas de aprobaci√≥n:\", diferencia_aprobacion)\n",
        "print(\"Diferencia en tasas de FPR:\", diferencia_fpr)\n",
        "print(\"Diferencia en tasas de FNR:\", diferencia_fnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GLDZhBP5t3J",
        "outputId": "0819527f-a6a8-4f31-c3fc-fa6a64a5b007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en tasas de aprobaci√≥n: 0.02048535497067938\n",
            "Diferencia en tasas de FPR: 0.014126538054430315\n",
            "Diferencia en tasas de FNR: 0.0016027387661738668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dIFERENCIA EN TASAS DE APROBACION: Esta  indica la discrepancia en la proporci√≥n de solicitudes aprobadas entre los grupos masculino y femeninO.Diferencia en tasas de FPR:discrepancia en la proporci√≥n de casos negativos incorrectamente clasificados como positivos entre los grupos masculino y femenino. Diferencia en tasas de FNR: discrepancia en la proporci√≥n de casos positivos incorrectamente clasificados como negativos entre los grupos masculino y femenino."
      ],
      "metadata": {
        "id": "ebfvTe2PASub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferencia en impacto en errores"
      ],
      "metadata": {
        "id": "0HOOLCv46MX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "definir una funci√≥n de p√©rdida que cuantifique el costo asociado con los falsos positivos y los falsos negativos. Luego SE calcula la p√©rdida esperada para cada grupo y encontrar la diferencia entre ellas. permitir√°n evaluar si los errores del modelo tienen un impacto desigual en hombres y mujeres y en qu√© medida."
      ],
      "metadata": {
        "id": "rqYSfyWvAoKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_perdida_esperada(y_true, y_pred, grupo):\n",
        "    if grupo == 0:  # Masculino\n",
        "        indices_grupo = np.where(df['applicant_sex'] == 0)[0]\n",
        "    elif grupo == 1:  # Femenino\n",
        "        indices_grupo = np.where(df['applicant_sex'].isin([1, 2]))[0]\n",
        "    else:\n",
        "        raise ValueError(\"El valor de grupo debe ser 0 (masculino) o 1 (femenino)\")\n",
        "\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "\n",
        "    # Definir funci√≥n de p√©rdida\n",
        "    # Por ejemplo, si queremos penalizar los falsos negativos m√°s que los falsos positivos\n",
        "    # Podemos usar una funci√≥n de p√©rdida como la p√©rdida cuadr√°tica\n",
        "    loss_fn = lambda y_true, y_pred: (y_true - y_pred) ** 2\n",
        "\n",
        "    perdida_esperada = np.mean(loss_fn(y_true_grupo, y_pred_grupo))\n",
        "    return perdida_esperada\n",
        "\n",
        "perdida_esperada_masculino = calcular_perdida_esperada(df['action_taken3'], predicciones, 0)\n",
        "perdida_esperada_femenino = calcular_perdida_esperada(df['action_taken3'], predicciones, 1)\n",
        "\n",
        "diferencia_perdida_esperada = np.abs(perdida_esperada_masculino - perdida_esperada_femenino)\n",
        "print(\"Diferencia en la p√©rdida esperada entre grupos masculino y femenino:\", diferencia_perdida_esperada)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO7lCTD46KeK",
        "outputId": "38602da2-50db-445b-c445-f805b2d5eae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en la p√©rdida esperada entre grupos masculino y femenino: 0.0006747936416952038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impacto Desigual - Falsos Positivos (FPR):"
      ],
      "metadata": {
        "id": "-U_cvYU86jTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr_masculino = calcular_fpr(df['action_taken3'], predicciones, 0)\n",
        "fpr_femenino = calcular_fpr(df['action_taken3'], predicciones, 1)\n",
        "\n",
        "diferencia_fpr = np.abs(fpr_masculino - fpr_femenino)\n",
        "print(\"Diferencia en la tasa de FPR entre grupos masculino y femenino:\", diferencia_fpr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5JzRbzA6fM0",
        "outputId": "2a435ee9-e898-485f-e0cb-ed94fd09e255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en la tasa de FPR entre grupos masculino y femenino: 0.014126538054430315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impacto Desigual - Falsos Negativos (FNR):"
      ],
      "metadata": {
        "id": "3Lp8ulPa6kdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnr_masculino = calcular_fnr(df['action_taken3'], predicciones, 0)\n",
        "fnr_femenino = calcular_fnr(df['action_taken3'], predicciones, 1)\n",
        "\n",
        "diferencia_fnr = np.abs(fnr_masculino - fnr_femenino)\n",
        "print(\"Diferencia en la tasa de FNR entre grupos masculino y femenino:\", diferencia_fnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZZqPNrO6o-T",
        "outputId": "c1376525-0d3f-4806-e381-3d026cb09625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en la tasa de FNR entre grupos masculino y femenino: 0.0016027387661738668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PARIDAD ESTADISTICACalcula la proporci√≥n de resultados positivos para cada nivel de applicant_sex\n",
        "proporcion_aprobacion_por_sex = {}\n",
        "for nivel in df['applicant_sex'].unique():\n",
        "    indices_nivel = df['applicant_sex'] == nivel\n",
        "    y_true_nivel = df['action_taken3'][indices_nivel]\n",
        "    y_pred_nivel = predicciones[indices_nivel]\n",
        "    aprobados = np.sum(y_pred_nivel == 1)\n",
        "    proporcion_aprobacion_por_sex[nivel] = aprobados / len(y_pred_nivel)\n",
        "\n",
        "# Calcula el SPD entre cada par de niveles de applicant_sex\n",
        "spd_por_sex_combinaciones = {}\n",
        "niveles_sex = df['applicant_sex'].unique()\n",
        "for i, nivel_1 in enumerate(niveles_sex):\n",
        "    for j, nivel_2 in enumerate(niveles_sex):\n",
        "        if i < j:\n",
        "            spd = abs(proporcion_aprobacion_por_sex[nivel_1] - proporcion_aprobacion_por_sex[nivel_2])\n",
        "            spd_por_sex_combinaciones[(nivel_1, nivel_2)] = spd\n",
        "\n",
        "# Imprime los resultados\n",
        "for combinacion, spd in spd_por_sex_combinaciones.items():\n",
        "    print(f\"SPD entre {combinacion[0]} y {combinacion[1]}: {spd}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp3fgZTa-xhF",
        "outputId": "1faf5bc0-bb65-42c6-db6e-84cb90b04f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPD entre 1 y 0: 0.020493657546035826\n",
            "SPD entre 1 y 2: 0.0028945551031769323\n",
            "SPD entre 0 y 2: 0.017599102442858894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtener los pares de niveles de applicant_sex y sus respectivos SPD\n",
        "pares_niveles_sex = list(spd_por_sex_combinaciones.keys())\n",
        "spd_valores = list(spd_por_sex_combinaciones.values())\n",
        "\n",
        "# Crear el gr√°fico de barras\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.bar(range(len(spd_valores)), spd_valores, color='skyblue')\n",
        "plt.xlabel('Pares de Niveles de applicant_sex')\n",
        "plt.ylabel('Diferencia de SPD')\n",
        "plt.title('Diferencias de Paridad Estad√≠stica (SPD) entre Niveles de applicant_sex')\n",
        "plt.xticks(range(len(spd_valores)), [f\"{par[0]} vs {par[1]}\" for par in pares_niveles_sex], rotation=90)\n",
        "\n",
        "# Cambiar etiquetas de los ejes x\n",
        "etiquetas_x = [f\"{par[0]} vs {par[1]}\" for par in pares_niveles_sex]\n",
        "etiquetas_x = [etiqueta.replace('0', 'Masculino') for etiqueta in etiquetas_x]\n",
        "etiquetas_x = [etiqueta.replace('1', 'Femenino') for etiqueta in etiquetas_x]\n",
        "etiquetas_x = [etiqueta.replace('2', 'Femenino') for etiqueta in etiquetas_x]\n",
        "plt.xticks(range(len(spd_valores)), etiquetas_x, rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "q0nrp235_R9Z",
        "outputId": "774f2a84-4339-4bbf-cf6d-8407ff166bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtener los pares de niveles de applicant_sex y sus respectivos SPD\n",
        "pares_niveles_sex = list(spd_por_sex_combinaciones.keys())\n",
        "spd_valores = list(spd_por_sex_combinaciones.values())\n",
        "\n",
        "# Filtrar pares de niveles que corresponden solo a hombres y mujeres\n",
        "pares_niveles_sex_filtrados = [par for par in pares_niveles_sex if 0 in par and (1 in par or 2 in par)]\n",
        "spd_valores_filtrados = [spd_por_sex_combinaciones[par] for par in pares_niveles_sex_filtrados]\n",
        "\n",
        "# Crear el gr√°fico de barras\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.bar(range(len(spd_valores_filtrados)), spd_valores_filtrados, color='skyblue')\n",
        "plt.xlabel('Pares de Niveles de applicant_sex')\n",
        "plt.ylabel('Diferencia de SPD')\n",
        "plt.title('Diferencias de Paridad Estad√≠stica (SPD) entre Hombres y Mujeres')\n",
        "plt.xticks(range(len(spd_valores_filtrados)), [f\"{par[0]} vs {par[1]}\" for par in pares_niveles_sex_filtrados], rotation=90)\n",
        "\n",
        "# Cambiar etiquetas de los ejes x\n",
        "etiquetas_x = [f\"{par[0]} vs {par[1]}\" for par in pares_niveles_sex_filtrados]\n",
        "etiquetas_x = [etiqueta.replace('0', 'Masculino') for etiqueta in etiquetas_x]\n",
        "etiquetas_x = [etiqueta.replace('1', 'Femenino') for etiqueta in etiquetas_x]\n",
        "etiquetas_x = [etiqueta.replace('2', 'Femenino') for etiqueta in etiquetas_x]\n",
        "plt.xticks(range(len(spd_valores_filtrados)), etiquetas_x, rotation=380)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "mVN0nLTagC7m",
        "outputId": "e2c1c6cc-0938-4e93-9ca7-7ae6de7ee8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METRICAS DE EQUIDAD POR EDAD"
      ],
      "metadata": {
        "id": "hyX4VSboA_GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def calcular_metricas_por_grupo_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "\n",
        "    precision = precision_score(y_true_grupo, y_pred_grupo)\n",
        "    recall = recall_score(y_true_grupo, y_pred_grupo)\n",
        "    f1 = f1_score(y_true_grupo, y_pred_grupo)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Definir grupos de edad\n",
        "grupos_edad = [1, 2, 0, 3, 4, 6, 5, 7]\n",
        "\n",
        "# Calcular m√©tricas por grupo de edad\n",
        "metricas_por_grupo_edad = {}\n",
        "for grupo in grupos_edad:\n",
        "    precision, recall, f1 = calcular_metricas_por_grupo_edad(df['action_taken3'], predicciones, grupo)\n",
        "    metricas_por_grupo_edad[grupo] = {'precision': precision, 'recall': recall, 'f1_score': f1}\n",
        "\n",
        "# Imprimir resultados\n",
        "for grupo, metricas in metricas_por_grupo_edad.items():\n",
        "    print(f\"M√©tricas para el grupo de edad {grupo}:\")\n",
        "    print(\"Precisi√≥n:\", metricas['precision'])\n",
        "    print(\"Recall:\", metricas['recall'])\n",
        "    print(\"F1-score:\", metricas['f1_score'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6ae79IQYsfo",
        "outputId": "f4d43533-25d6-48fa-a4ca-bbfd58fde2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©tricas para el grupo de edad 1:\n",
            "Precisi√≥n: 0.8537407929791568\n",
            "Recall: 0.866207887857838\n",
            "F1-score: 0.85992915638003\n",
            "M√©tricas para el grupo de edad 2:\n",
            "Precisi√≥n: 0.8270172812627569\n",
            "Recall: 0.870750297282196\n",
            "F1-score: 0.8483205270467378\n",
            "M√©tricas para el grupo de edad 0:\n",
            "Precisi√≥n: 0.8754481909383941\n",
            "Recall: 0.8708935918776166\n",
            "F1-score: 0.8731649520286672\n",
            "M√©tricas para el grupo de edad 3:\n",
            "Precisi√≥n: 0.8172931678097057\n",
            "Recall: 0.8661379652970725\n",
            "F1-score: 0.841006950027693\n",
            "M√©tricas para el grupo de edad 4:\n",
            "Precisi√≥n: 0.8169741251773799\n",
            "Recall: 0.864283889101827\n",
            "F1-score: 0.8399633705319033\n",
            "M√©tricas para el grupo de edad 6:\n",
            "Precisi√≥n: 0.7717661691542289\n",
            "Recall: 0.8585688871318442\n",
            "F1-score: 0.8128567418358753\n",
            "M√©tricas para el grupo de edad 5:\n",
            "Precisi√≥n: 0.8683429720895147\n",
            "Recall: 0.8505492340278804\n",
            "F1-score: 0.8593540038819489\n",
            "M√©tricas para el grupo de edad 7:\n",
            "Precisi√≥n: 0.9335335062099086\n",
            "Recall: 0.9966486959055807\n",
            "F1-score: 0.9640591966173362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calcular_precision_por_grupo_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    precision_grupo = np.mean(y_true_grupo == y_pred_grupo)\n",
        "    return precision_grupo\n",
        "\n",
        "# Definir grupos de edad y sus etiquetas correspondientes\n",
        "grupos_edad = [1, 2, 0, 3, 4, 6, 5, 7]\n",
        "etiquetas_edad = ['35-44', '45-54', '25-34', '55-64', '65-74', '>74', '<25', 'sin info']\n",
        "\n",
        "# Calcular precisiones por grupo de edad\n",
        "precision_por_grupo_edad = [calcular_precision_por_grupo_edad(df['action_taken3'], predicciones, grupo) for grupo in grupos_edad]\n",
        "\n",
        "# Graficar las precisiones por grupo de edad\n",
        "plt.bar(etiquetas_edad, precision_por_grupo_edad, color='lightblue')  # Cambio de color a azul claro\n",
        "plt.xlabel('Grupo de Edad')\n",
        "plt.ylabel('Precisi√≥n')\n",
        "plt.title('Precisi√≥n por Grupo de Edad')\n",
        "plt.xticks(rotation=45)  # Rotar las etiquetas en el eje x para mejorar la legibilidad\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "tW4xGFcJBQro",
        "outputId": "b9f5c1c5-e464-4acf-c233-560e4d351e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define grupos de edad con etiquetas descriptivas\n",
        "grupos_edad = {\n",
        "    0: '<25',\n",
        "    1: '25-34',\n",
        "    2: '35-44',\n",
        "    3: '45-54',\n",
        "    4: '55-64',\n",
        "    5: '65-74',\n",
        "    6: '>74',\n",
        "    7: 'sin info'\n",
        "}\n",
        "\n",
        "def calcular_proporcion_aprobacion_por_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    aprobados = np.sum(y_pred_grupo == 1)\n",
        "    proporcion_aprobacion = aprobados / len(y_pred_grupo)\n",
        "    return proporcion_aprobacion\n",
        "\n",
        "def calcular_fpr_por_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    falsos_positivos = np.sum((y_true_grupo == 0) & (y_pred_grupo == 1))\n",
        "    negativos_reales = np.sum(y_true_grupo == 0)\n",
        "    fpr = falsos_positivos / negativos_reales\n",
        "    return fpr\n",
        "\n",
        "def calcular_fnr_por_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    falsos_negativos = np.sum((y_true_grupo == 1) & (y_pred_grupo == 0))\n",
        "    positivos_reales = np.sum(y_true_grupo == 1)\n",
        "    fnr = falsos_negativos / positivos_reales\n",
        "    return fnr\n",
        "\n",
        "def calcular_diferencia_aprobacion_por_edad(y_true, y_pred):\n",
        "    proporcion_aprobacion_por_edad = {}\n",
        "    for grupo, etiqueta in grupos_edad.items():\n",
        "        proporcion_aprobacion_por_edad[etiqueta] = calcular_proporcion_aprobacion_por_edad(y_true, y_pred, grupo)\n",
        "    diferencia_aprobacion = max(proporcion_aprobacion_por_edad.values()) - min(proporcion_aprobacion_por_edad.values())\n",
        "    return diferencia_aprobacion\n",
        "\n",
        "def calcular_diferencia_fpr_por_edad(y_true, y_pred):\n",
        "    fpr_por_edad = {}\n",
        "    for grupo, etiqueta in grupos_edad.items():\n",
        "        fpr_por_edad[etiqueta] = calcular_fpr_por_edad(y_true, y_pred, grupo)\n",
        "    diferencia_fpr = max(fpr_por_edad.values()) - min(fpr_por_edad.values())\n",
        "    return diferencia_fpr\n",
        "\n",
        "def calcular_diferencia_fnr_por_edad(y_true, y_pred):\n",
        "    fnr_por_edad = {}\n",
        "    for grupo, etiqueta in grupos_edad.items():\n",
        "        fnr_por_edad[etiqueta] = calcular_fnr_por_edad(y_true, y_pred, grupo)\n",
        "    diferencia_fnr = max(fnr_por_edad.values()) - min(fnr_por_edad.values())\n",
        "    return diferencia_fnr\n",
        "\n",
        "# Calcular m√©tricas\n",
        "diferencia_aprobacion_por_edad = calcular_diferencia_aprobacion_por_edad(df['action_taken3'], predicciones)\n",
        "diferencia_fpr_por_edad = calcular_diferencia_fpr_por_edad(df['action_taken3'], predicciones)\n",
        "diferencia_fnr_por_edad = calcular_diferencia_fnr_por_edad(df['action_taken3'], predicciones)\n",
        "\n",
        "print(\"Diferencia en tasas de aprobaci√≥n por edad:\", diferencia_aprobacion_por_edad)\n",
        "print(\"Diferencia en tasas de FPR por edad:\", diferencia_fpr_por_edad)\n",
        "print(\"Diferencia en tasas de FNR por edad:\", diferencia_fnr_por_edad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiQ3sUjQ726b",
        "outputId": "cb15f740-c889-4169-9f04-6e0bb1e917d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en tasas de aprobaci√≥n por edad: 0.36961221345192785\n",
            "Diferencia en tasas de FPR por edad: 0.41079694384027665\n",
            "Diferencia en tasas de FNR por edad: 0.14609946187770023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difrencia en impacto de errores"
      ],
      "metadata": {
        "id": "mNIJrKcy8jjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_perdida_esperada_por_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "\n",
        "    # Definir funci√≥n de p√©rdida\n",
        "    # Por ejemplo, si queremos penalizar los falsos negativos m√°s que los falsos positivos\n",
        "    # Podemos usar una funci√≥n de p√©rdida como la p√©rdida cuadr√°tica\n",
        "    loss_fn = lambda y_true, y_pred: (y_true - y_pred) ** 2\n",
        "\n",
        "    perdida_esperada = np.mean(loss_fn(y_true_grupo, y_pred_grupo))\n",
        "    return perdida_esperada\n",
        "\n",
        "# Calcular la p√©rdida esperada para cada grupo de edad\n",
        "perdida_esperada_por_edad = {}\n",
        "for grupo in df['applicant_age'].unique():\n",
        "    perdida_esperada_por_edad[grupo] = calcular_perdida_esperada_por_edad(df['action_taken3'], predicciones, grupo)\n",
        "\n",
        "# Calcular la diferencia en la p√©rdida esperada\n",
        "diferencia_perdida_esperada_por_edad = max(perdida_esperada_por_edad.values()) - min(perdida_esperada_por_edad.values())\n",
        "\n",
        "print(\"Diferencia en la p√©rdida esperada por edad:\", diferencia_perdida_esperada_por_edad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dBXVQvB8lDh",
        "outputId": "56ecd604-5768-45ab-e385-5177d43cbde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en la p√©rdida esperada por edad: 0.1456789546168869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impacto Desigual - Falsos Positivos (FPR):"
      ],
      "metadata": {
        "id": "8dWB3UU789nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_fpr_por_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    falsos_positivos = np.sum((y_true_grupo == 0) & (y_pred_grupo == 1))\n",
        "    negativos_reales = np.sum(y_true_grupo == 0)\n",
        "    fpr = falsos_positivos / negativos_reales\n",
        "    return fpr\n",
        "\n",
        "# Calcular FPR para cada grupo de edad\n",
        "fpr_por_edad = {}\n",
        "for grupo in df['applicant_age'].unique():\n",
        "    fpr_por_edad[grupo] = calcular_fpr_por_edad(df['action_taken3'], predicciones, grupo)\n",
        "\n",
        "# Calcular la diferencia en la tasa de FPR entre grupos de edad\n",
        "diferencia_fpr_por_edad = max(fpr_por_edad.values()) - min(fpr_por_edad.values())\n",
        "\n",
        "print(\"Diferencia en la tasa de FPR entre grupos de edad:\", diferencia_fpr_por_edad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twy6T54t8-F5",
        "outputId": "32904328-6acd-4c5b-86ef-be20882e5628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en la tasa de FPR entre grupos de edad: 0.41079694384027665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impacto Desigual - Falsos Negativos (FNR):"
      ],
      "metadata": {
        "id": "icTbQrNw8-tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_fnr_por_edad(y_true, y_pred, grupo):\n",
        "    indices_grupo = np.where(df['applicant_age'] == grupo)[0]\n",
        "    y_true_grupo = y_true[indices_grupo]\n",
        "    y_pred_grupo = y_pred[indices_grupo]\n",
        "    falsos_negativos = np.sum((y_true_grupo == 1) & (y_pred_grupo == 0))\n",
        "    positivos_reales = np.sum(y_true_grupo == 1)\n",
        "    fnr = falsos_negativos / positivos_reales\n",
        "    return fnr\n",
        "\n",
        "# Calcular FNR para cada grupo de edad\n",
        "fnr_por_edad = {}\n",
        "for grupo in df['applicant_age'].unique():\n",
        "    fnr_por_edad[grupo] = calcular_fnr_por_edad(df['action_taken3'], predicciones, grupo)\n",
        "\n",
        "# Calcular la diferencia en la tasa de FNR entre grupos de edad\n",
        "diferencia_fnr_por_edad = max(fnr_por_edad.values()) - min(fnr_por_edad.values())\n",
        "\n",
        "print(\"Diferencia en la tasa de FNR entre grupos de edad:\", diferencia_fnr_por_edad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2qBNw5t9C3z",
        "outputId": "81cb2272-b2a6-47a7-80c8-d13218238be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia en la tasa de FNR entre grupos de edad: 0.14609946187770023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supongamos que ya tienes cargados tus datos en un DataFrame llamado df\n",
        "# Aqu√≠ definir√© un DataFrame de ejemplo para ilustrar el proceso\n",
        "data = {\n",
        "    'grupo_edad': ['<25', '25-34', '35-44', '45-54', '<25', '35-44', '25-34'],  # Ejemplo de grupos de edad\n",
        "    'aprobacion': [1, 0, 1, 1, 0, 1, 1]                                           # Ejemplo de aprobaciones (1) y rechazos (0)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calcular la proporci√≥n de aprobaciones por grupo de edad\n",
        "proporcion_aprobacion_por_edad = df.groupby('grupo_edad')['aprobacion'].mean()\n",
        "\n",
        "print(proporcion_aprobacion_por_edad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yQKyFy35h_W",
        "outputId": "f2538b3c-c9f9-4752-ef39-b129d7c4f61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grupo_edad\n",
            "25-34    0.5\n",
            "35-44    1.0\n",
            "45-54    1.0\n",
            "<25      0.5\n",
            "Name: aprobacion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grupos de edad con etiquetas descriptivas\n",
        "grupos_edad = {\n",
        "    0: '<25',\n",
        "    1: '25-34',\n",
        "    2: '35-44',\n",
        "    3: '45-54',\n",
        "    4: '55-64',\n",
        "    5: '65-74',\n",
        "    6: '>74',\n",
        "    7: 'sin info'\n",
        "}\n",
        "\n",
        "# Supongamos que ya has calculado las proporciones de aprobaci√≥n por grupo de edad\n",
        "proporcion_aprobacion_por_edad = {\n",
        "    '<25': 0.75,\n",
        "    '25-34': 0.80,\n",
        "    '35-44': 0.70,\n",
        "    '45-54': 0.65,\n",
        "    '55-64': 0.60,\n",
        "    '65-74': 0.55,\n",
        "    '>74': 0.50,\n",
        "    'sin info': 0.45\n",
        "}\n",
        "\n",
        "# Calcular el SPD para todas las combinaciones de pares de grupos de edad\n",
        "for grupo_1 in grupos_edad.values():\n",
        "    for grupo_2 in grupos_edad.values():\n",
        "        if grupo_1 != grupo_2:\n",
        "            spd_por_edad = abs(proporcion_aprobacion_por_edad[grupo_1] - proporcion_aprobacion_por_edad[grupo_2])\n",
        "            print(\"Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad\", grupo_1, \"y\", grupo_2, \":\", spd_por_edad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOwFvH8t-Cla",
        "outputId": "ebb9a047-3861-4b7e-a891-d186264e3687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y 25-34 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y 35-44 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y 45-54 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y 55-64 : 0.15000000000000002\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y 65-74 : 0.19999999999999996\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y >74 : 0.25\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad <25 y sin info : 0.3\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y <25 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y 35-44 : 0.10000000000000009\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y 45-54 : 0.15000000000000002\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y 55-64 : 0.20000000000000007\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y 65-74 : 0.25\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y >74 : 0.30000000000000004\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 25-34 y sin info : 0.35000000000000003\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y <25 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y 25-34 : 0.10000000000000009\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y 45-54 : 0.04999999999999993\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y 55-64 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y 65-74 : 0.1499999999999999\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y >74 : 0.19999999999999996\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 35-44 y sin info : 0.24999999999999994\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y <25 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y 25-34 : 0.15000000000000002\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y 35-44 : 0.04999999999999993\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y 55-64 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y 65-74 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y >74 : 0.15000000000000002\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 45-54 y sin info : 0.2\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y <25 : 0.15000000000000002\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y 25-34 : 0.20000000000000007\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y 35-44 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y 45-54 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y 65-74 : 0.04999999999999993\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y >74 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 55-64 y sin info : 0.14999999999999997\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y <25 : 0.19999999999999996\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y 25-34 : 0.25\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y 35-44 : 0.1499999999999999\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y 45-54 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y 55-64 : 0.04999999999999993\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y >74 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad 65-74 y sin info : 0.10000000000000003\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y <25 : 0.25\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y 25-34 : 0.30000000000000004\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y 35-44 : 0.19999999999999996\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y 45-54 : 0.15000000000000002\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y 55-64 : 0.09999999999999998\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y 65-74 : 0.050000000000000044\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad >74 y sin info : 0.04999999999999999\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y <25 : 0.3\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y 25-34 : 0.35000000000000003\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y 35-44 : 0.24999999999999994\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y 45-54 : 0.2\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y 55-64 : 0.14999999999999997\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y 65-74 : 0.10000000000000003\n",
            "Diferencia de paridad estad√≠stica (SPD) entre los grupos de edad sin info y >74 : 0.04999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define grupos de edad con etiquetas descriptivas\n",
        "grupos_edad = {\n",
        "    0: '<25',\n",
        "    1: '25-34',\n",
        "    2: '35-44',\n",
        "    3: '45-54',\n",
        "    4: '55-64',\n",
        "    5: '65-74',\n",
        "    6: '>74',\n",
        "    7: 'sin info'\n",
        "}\n",
        "\n",
        "# Supongamos que ya has calculado las proporciones de aprobaci√≥n por grupo de edad\n",
        "proporcion_aprobacion_por_edad = {\n",
        "    '<25': 0.75,\n",
        "    '25-34': 0.80,\n",
        "    '35-44': 0.70,\n",
        "    '45-54': 0.65,\n",
        "    '55-64': 0.60,\n",
        "    '65-74': 0.55,\n",
        "    '>74': 0.50,\n",
        "    'sin info': 0.45\n",
        "}\n",
        "\n",
        "# Calcular el SPD para todas las combinaciones de pares de grupos de edad\n",
        "spd_por_edad = np.zeros((len(grupos_edad), len(grupos_edad)))\n",
        "for i, grupo_1 in enumerate(grupos_edad.values()):\n",
        "    for j, grupo_2 in enumerate(grupos_edad.values()):\n",
        "        if grupo_1 != grupo_2:\n",
        "            spd_por_edad[i, j] = abs(proporcion_aprobacion_por_edad[grupo_1] - proporcion_aprobacion_por_edad[grupo_2])\n",
        "\n",
        "# Crear un mapa de calor para visualizar el SPD\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(spd_por_edad, cmap='coolwarm', interpolation='nearest')\n",
        "plt.colorbar(label='Diferencia de paridad estad√≠stica (SPD)')\n",
        "plt.xticks(range(len(grupos_edad)), list(grupos_edad.values()), rotation=45)\n",
        "plt.yticks(range(len(grupos_edad)), list(grupos_edad.values()))\n",
        "plt.title('Diferencia de paridad estad√≠stica (SPD) entre grupos de edad')\n",
        "plt.xlabel('Grupo de edad')\n",
        "plt.ylabel('Grupo de edad')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "NxIp4v39HUvn",
        "outputId": "3731ca46-03be-48c8-efad-6975a727fb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impacto Dispar EDAD"
      ],
      "metadata": {
        "id": "SyhssgzwSGM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grupos de edad con etiquetas descriptivas\n",
        "grupos_edad = {\n",
        "    0: '<25',\n",
        "    1: '25-34',\n",
        "    2: '35-44',\n",
        "    3: '45-54',\n",
        "    4: '55-64',\n",
        "    5: '65-74',\n",
        "    6: '>74',\n",
        "    7: 'sin info'\n",
        "}\n",
        "\n",
        "# Supongamos que ya has calculado las proporciones de aprobaci√≥n por grupo de edad\n",
        "proporcion_aprobacion_por_edad = {\n",
        "    '<25': 0.75,\n",
        "    '25-34': 0.80,\n",
        "    '35-44': 0.70,\n",
        "    '45-54': 0.65,\n",
        "    '55-64': 0.60,\n",
        "    '65-74': 0.55,\n",
        "    '>74': 0.50,\n",
        "    'sin info': 0.45\n",
        "}\n",
        "\n",
        "# Definir los grupos de edad que deseas comparar\n",
        "grupo_referencia = '<25'  # Por ejemplo, el grupo <25\n",
        "grupo_comparacion = '35-44'  # Por ejemplo, el grupo 35-44\n",
        "\n",
        "# Calcular el Impacto Dispar entre los grupos de edad para la proporci√≥n de aprobaci√≥n\n",
        "impacto_dispar_proporcion_aprobacion = proporcion_aprobacion_por_edad[grupo_referencia] - proporcion_aprobacion_por_edad[grupo_comparacion]\n",
        "\n",
        "print(\"Impacto Dispar entre los grupos de edad\", grupo_referencia, \"y\", grupo_comparacion, \"para la proporci√≥n de aprobaci√≥n:\", impacto_dispar_proporcion_aprobacion)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rmQLxHIR8fF",
        "outputId": "607e89be-c33b-4198-d1d0-e106f072f647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Impacto Dispar entre los grupos de edad <25 y 35-44 para la proporci√≥n de aprobaci√≥n: 0.050000000000000044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grupos de edad con etiquetas descriptivas\n",
        "grupos_edad = {\n",
        "    0: '<25',\n",
        "    1: '25-34',\n",
        "    2: '35-44',\n",
        "    3: '45-54',\n",
        "    4: '55-64',\n",
        "    5: '65-74',\n",
        "    6: '>74',\n",
        "    7: 'sin info'\n",
        "}\n",
        "\n",
        "# Supongamos que ya has calculado las proporciones de aprobaci√≥n por grupo de edad\n",
        "proporcion_aprobacion_por_edad = {\n",
        "    '<25': 0.75,\n",
        "    '25-34': 0.80,\n",
        "    '35-44': 0.70,\n",
        "    '45-54': 0.65,\n",
        "    '55-64': 0.60,\n",
        "    '65-74': 0.55,\n",
        "    '>74': 0.50,\n",
        "    'sin info': 0.45\n",
        "}\n",
        "\n",
        "# Definir el grupo de referencia\n",
        "grupo_referencia = '<25'  # Por ejemplo, el grupo <25\n",
        "\n",
        "# Calcular el Impacto Dispar entre el grupo de referencia y cada uno de los otros grupos de edad\n",
        "impacto_dispar_por_grupo = {}\n",
        "for grupo, proporci√≥n in proporcion_aprobacion_por_edad.items():\n",
        "    if grupo != grupo_referencia:\n",
        "        impacto_dispar_por_grupo[grupo] = proporcion_aprobacion_por_edad[grupo_referencia] - proporci√≥n\n",
        "\n",
        "# Imprimir el Impacto Dispar para cada grupo de edad\n",
        "for grupo, impacto_dispar in impacto_dispar_por_grupo.items():\n",
        "    print(\"Impacto Dispar entre los grupos de edad\", grupo_referencia, \"y\", grupo, \":\", impacto_dispar)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2VgkNkLAUTK",
        "outputId": "1296ceca-e60d-4b65-d40d-13a07916fccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Impacto Dispar entre los grupos de edad <25 y 25-34 : -0.050000000000000044\n",
            "Impacto Dispar entre los grupos de edad <25 y 35-44 : 0.050000000000000044\n",
            "Impacto Dispar entre los grupos de edad <25 y 45-54 : 0.09999999999999998\n",
            "Impacto Dispar entre los grupos de edad <25 y 55-64 : 0.15000000000000002\n",
            "Impacto Dispar entre los grupos de edad <25 y 65-74 : 0.19999999999999996\n",
            "Impacto Dispar entre los grupos de edad <25 y >74 : 0.25\n",
            "Impacto Dispar entre los grupos de edad <25 y sin info : 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define grupos de edad con etiquetas descriptivas\n",
        "grupos_edad = {\n",
        "    0: '<25',\n",
        "    1: '25-34',\n",
        "    2: '35-44',\n",
        "    3: '45-54',\n",
        "    4: '55-64',\n",
        "    5: '65-74',\n",
        "    6: '>74',\n",
        "    7: 'sin info'\n",
        "}\n",
        "\n",
        "# Supongamos que ya has calculado las proporciones de aprobaci√≥n por grupo de edad\n",
        "proporcion_aprobacion_por_edad = {\n",
        "    '<25': 0.75,\n",
        "    '25-34': 0.80,\n",
        "    '35-44': 0.70,\n",
        "    '45-54': 0.65,\n",
        "    '55-64': 0.60,\n",
        "    '65-74': 0.55,\n",
        "    '>74': 0.50,\n",
        "    'sin info': 0.45\n",
        "}\n",
        "\n",
        "# Definir el grupo de referencia\n",
        "grupo_referencia = '<25'  # Por ejemplo, el grupo <25\n",
        "\n",
        "# Calcular el Impacto Dispar entre el grupo de referencia y cada uno de los otros grupos de edad\n",
        "impacto_dispar_por_grupo = {}\n",
        "for grupo, proporci√≥n in proporcion_aprobacion_por_edad.items():\n",
        "    if grupo != grupo_referencia:\n",
        "        impacto_dispar_por_grupo[grupo] = proporcion_aprobacion_por_edad[grupo_referencia] - proporci√≥n\n",
        "\n",
        "# Mostrar el Impacto Dispar en un gr√°fico de barras\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(impacto_dispar_por_grupo.keys(), impacto_dispar_por_grupo.values(), color='skyblue')\n",
        "plt.xlabel('Grupo de Edad')\n",
        "plt.ylabel('Impacto Dispar')\n",
        "plt.title(f'Impacto Dispar respecto al grupo de referencia: {grupo_referencia}')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rit80opRHiq3",
        "outputId": "1e557984-e089-4cb4-ff82-5e8591257e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fairlearn: REESTRICCION DE EQUIDAD"
      ],
      "metadata": {
        "id": "K0NJUmc6lszN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.modeldifferently.com/2023/10/como-evitar-sesgos-en-un-algoritmo/#la-%C3%A9tica-en-machine-learning-qu%C3%A9-entendemos-por-%C3%A9tica"
      ],
      "metadata": {
        "id": "RwolOrDQl2-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fairlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XpN8mYuugXm",
        "outputId": "2c13bc08-7c64-4459-e8a3-f5ecc59ddbae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/234.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.4/234.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import GridSearch\n",
        "from fairlearn.reductions import DemographicParity\n",
        "from fairlearn.metrics import MetricFrame\n",
        "from fairlearn.reductions import GridSearch, DemographicParity\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from fairlearn.metrics import demographic_parity_difference\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "R_UwnTSNt1pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import GridSearch\n",
        "from fairlearn.reductions import DemographicParity\n",
        "from fairlearn.metrics import MetricFrame"
      ],
      "metadata": {
        "id": "1sFTnvRlku64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo con reestriccion de pARIDAD ESTADISTICA\n",
        "from fairlearn.reductions import DemographicParity, GridSearch\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creamos el modelo LGBMClassifier\n",
        "lgbm_model = LGBMClassifier()\n",
        "\n",
        "# Creamos el pipeline con el modelo LGBM y el escalador\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Puedes agregar un escalador si es necesario\n",
        "    ('lgbm', lgbm_model)\n",
        "])\n",
        "\n",
        "# Creamos el mitigador de sesgo para el modelo\n",
        "sweep = GridSearch(\n",
        "    pipeline,  # Usamos nuestro pipeline con el modelo LGBM\n",
        "    constraints=DemographicParity(),  # La m√©trica que queremos optimizar\n",
        "    grid_size=40,\n",
        "    sample_weight_name='lgbm__sample_weight'  # Especificamos el nombre del par√°metro de peso de muestra\n",
        ")\n",
        "\n",
        "# Entrenamos el mitigador de sesgo\n",
        "sweep.fit(X_train, y_train, sensitive_features=X_train[['applicant_sex']])\n",
        "\n",
        "# Seleccionamos el mejor modelo seg√∫n la m√©trica de equidad\n",
        "sweep_preds = [predictor.predict(X_test) for predictor in sweep.predictors_]\n",
        "sweep_scores = [accuracy_score(y_test, preds) for preds in sweep_preds]\n",
        "best_model_index = np.argmax(sweep_scores)\n",
        "best_model = sweep.predictors_[best_model_index]\n",
        "\n",
        "# Evaluamos el modelo seleccionado\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlxhT2eemLJp",
        "outputId": "40b19975-8e29-48f1-b49d-e44ae25719d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 354230, number of negative: 445770\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023347 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.605838 -> initscore=0.429853\n",
            "[LightGBM] [Info] Start training from score 0.429853\n",
            "[LightGBM] [Info] Number of positive: 522917, number of negative: 277083\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044349 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.652734 -> initscore=0.631079\n",
            "[LightGBM] [Info] Start training from score 0.631079\n",
            "[LightGBM] [Info] Number of positive: 354230, number of negative: 445770\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027016 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624659 -> initscore=0.509369\n",
            "[LightGBM] [Info] Start training from score 0.509369\n",
            "[LightGBM] [Info] Number of positive: 534474, number of negative: 265526\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023980 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.586135 -> initscore=0.348011\n",
            "[LightGBM] [Info] Start training from score 0.348011\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 619001, number of negative: 180999\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039541 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655899 -> initscore=0.645073\n",
            "[LightGBM] [Info] Start training from score 0.645073\n",
            "[LightGBM] [Info] Number of positive: 522917, number of negative: 277083\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024038 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654126 -> initscore=0.637225\n",
            "[LightGBM] [Info] Start training from score 0.637225\n",
            "[LightGBM] [Info] Number of positive: 354230, number of negative: 445770\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023876 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.651619 -> initscore=0.626165\n",
            "[LightGBM] [Info] Start training from score 0.626165\n",
            "[LightGBM] [Info] Number of positive: 354683, number of negative: 445317\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038346 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.605592 -> initscore=0.428821\n",
            "[LightGBM] [Info] Start training from score 0.428821\n",
            "[LightGBM] [Info] Number of positive: 534927, number of negative: 265073\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042330 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.572479 -> initscore=0.291974\n",
            "[LightGBM] [Info] Start training from score 0.291974\n",
            "[LightGBM] [Info] Number of positive: 264771, number of negative: 535229\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023516 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.599542 -> initscore=0.403555\n",
            "[LightGBM] [Info] Start training from score 0.403555\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 619001, number of negative: 180999\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023772 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.640172 -> initscore=0.576110\n",
            "[LightGBM] [Info] Start training from score 0.576110\n",
            "[LightGBM] [Info] Number of positive: 522917, number of negative: 277083\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023479 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655543 -> initscore=0.643496\n",
            "[LightGBM] [Info] Start training from score 0.643496\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.652905 -> initscore=0.631833\n",
            "[LightGBM] [Info] Start training from score 0.631833\n",
            "[LightGBM] [Info] Number of positive: 354683, number of negative: 445317\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022872 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624260 -> initscore=0.507670\n",
            "[LightGBM] [Info] Start training from score 0.507670\n",
            "[LightGBM] [Info] Number of positive: 534927, number of negative: 265073\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022877 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585849 -> initscore=0.346830\n",
            "[LightGBM] [Info] Start training from score 0.346830\n",
            "[LightGBM] [Info] Number of positive: 534927, number of negative: 265073\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023003 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562561 -> initscore=0.251563\n",
            "[LightGBM] [Info] Start training from score 0.251563\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 264771, number of negative: 535229\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037953 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.560494 -> initscore=0.243166\n",
            "[LightGBM] [Info] Start training from score 0.243166\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 264771, number of negative: 535229\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582020 -> initscore=0.331070\n",
            "[LightGBM] [Info] Start training from score 0.331070\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 264771, number of negative: 535229\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024231 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627327 -> initscore=0.520766\n",
            "[LightGBM] [Info] Start training from score 0.520766\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 619454, number of negative: 180546\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033888 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.656486 -> initscore=0.647673\n",
            "[LightGBM] [Info] Start training from score 0.647673\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 354683, number of negative: 445317\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040022 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650947 -> initscore=0.623203\n",
            "[LightGBM] [Info] Start training from score 0.623203\n",
            "[LightGBM] [Info] Number of positive: 354683, number of negative: 445317\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023247 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.605265 -> initscore=0.427453\n",
            "[LightGBM] [Info] Start training from score 0.427453\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 535229, number of negative: 264771\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039885 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.572264 -> initscore=0.291093\n",
            "[LightGBM] [Info] Start training from score 0.291093\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 535229, number of negative: 264771\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023461 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555016 -> initscore=0.220958\n",
            "[LightGBM] [Info] Start training from score 0.220958\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 264771, number of negative: 535229\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023425 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.569743 -> initscore=0.280803\n",
            "[LightGBM] [Info] Start training from score 0.280803\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 265224, number of negative: 534776\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025743 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.599964 -> initscore=0.405314\n",
            "[LightGBM] [Info] Start training from score 0.405314\n",
            "[LightGBM] [Info] Number of positive: 619454, number of negative: 180546\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039351 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.640573 -> initscore=0.577853\n",
            "[LightGBM] [Info] Start training from score 0.577853\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023190 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655543 -> initscore=0.643493\n",
            "[LightGBM] [Info] Start training from score 0.643493\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.652904 -> initscore=0.631830\n",
            "[LightGBM] [Info] Start training from score 0.631830\n",
            "[LightGBM] [Info] Number of positive: 354985, number of negative: 445015\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039806 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623770 -> initscore=0.505582\n",
            "[LightGBM] [Info] Start training from score 0.505582\n",
            "[LightGBM] [Info] Number of positive: 535229, number of negative: 264771\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022988 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585528 -> initscore=0.345509\n",
            "[LightGBM] [Info] Start training from score 0.345509\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 265224, number of negative: 534776\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582281 -> initscore=0.332145\n",
            "[LightGBM] [Info] Start training from score 0.332145\n",
            "[LightGBM] [Info] Number of positive: 619454, number of negative: 180546\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025412 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627598 -> initscore=0.521926\n",
            "[LightGBM] [Info] Start training from score 0.521926\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042677 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.656896 -> initscore=0.649491\n",
            "[LightGBM] [Info] Start training from score 0.649491\n",
            "[LightGBM] [Info] Number of positive: 523672, number of negative: 276328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041602 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654154 -> initscore=0.637347\n",
            "[LightGBM] [Info] Start training from score 0.637347\n",
            "[LightGBM] [Info] Number of positive: 354985, number of negative: 445015\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023211 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650169 -> initscore=0.619783\n",
            "[LightGBM] [Info] Start training from score 0.619783\n",
            "[LightGBM] [Info] Number of positive: 265224, number of negative: 534776\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022957 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.600316 -> initscore=0.406780\n",
            "[LightGBM] [Info] Start training from score 0.406780\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 619756, number of negative: 180244\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023177 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.640855 -> initscore=0.579079\n",
            "[LightGBM] [Info] Start training from score 0.579079\n",
            "[LightGBM] [Info] Number of positive: 523672, number of negative: 276328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022947 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655423 -> initscore=0.642965\n",
            "[LightGBM] [Info] Start training from score 0.642965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la precisi√≥n\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmLkeojUqacf",
        "outputId": "7f6f4257-b93b-416c-a389-0f7e173ceb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.806605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la precisi√≥n por grupo de sexo y raza\n",
        "sensitive_features_test = X_test[['applicant_sex']]\n",
        "metrics = MetricFrame(metrics={'precision': precision_score, 'recall': recall_score},\n",
        "                      y_true=y_test,\n",
        "                      y_pred=predictions,\n",
        "                      sensitive_features=sensitive_features_test)\n",
        "\n",
        "# Obtener los valores de las m√©tricas por grupo\n",
        "group_metrics = metrics.by_group\n",
        "\n",
        "# Imprimir las m√©tricas por grupo de una manera controlada\n",
        "print(\"Precision and recall by applicant_sex:\")\n",
        "for group, metrics in group_metrics.iterrows():\n",
        "    print(f\"Applicant_sex: {group}\")\n",
        "    print(f\"Precision: {metrics['precision']}\")\n",
        "    print(f\"Recall: {metrics['recall']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZhcC6WxqeUa",
        "outputId": "4b1c0ca7-dfcf-40ac-96e2-1d10c3dba89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision and recall by applicant_sex:\n",
            "Applicant_sex: 0\n",
            "Precision: 0.8443543185718815\n",
            "Recall: 0.8711820437626889\n",
            "\n",
            "Applicant_sex: 1\n",
            "Precision: 0.8329454711384896\n",
            "Recall: 0.8656312981624185\n",
            "\n",
            "Applicant_sex: 2\n",
            "Precision: 0.819672131147541\n",
            "Recall: 0.9174311926605505\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo con reestriccion Igualdad FALSOS POSITIVOS\n",
        "from fairlearn.reductions import ErrorRateParity, GridSearch\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creamos un nuevo modelo LGBMClassifier para el ajuste de equidad en falsos positivos\n",
        "lgbm_model_eq_fp = LGBMClassifier()\n",
        "\n",
        "# Creamos un nuevo pipeline con el modelo LGBM y el escalador para el ajuste de equidad en falsos positivos\n",
        "pipeline_eq_fp = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lgbm', lgbm_model_eq_fp)\n",
        "])\n",
        "\n",
        "# Creamos el mitigador de sesgo para el ajuste de equidad en falsos positivos\n",
        "sweep_eq_fp = GridSearch(\n",
        "    pipeline_eq_fp,\n",
        "    constraints=ErrorRateParity(),\n",
        "    grid_size=40,\n",
        "    sample_weight_name='lgbm__sample_weight'\n",
        ")\n",
        "\n",
        "# Entrenamos el mitigador de sesgo para el ajuste de equidad en falsos positivos\n",
        "sweep_eq_fp.fit(X_train, y_train, sensitive_features=X_train[['applicant_sex']])\n",
        "\n",
        "# Seleccionamos el mejor modelo seg√∫n la m√©trica de equidad en falsos positivos\n",
        "sweep_preds_eq_fp = [predictor.predict(X_test) for predictor in sweep_eq_fp.predictors_]\n",
        "sweep_scores_eq_fp = [accuracy_score(y_test, preds) for preds in sweep_preds_eq_fp]\n",
        "best_model_index_eq_fp = np.argmax(sweep_scores_eq_fp)\n",
        "best_model_eq_fp = sweep_eq_fp.predictors_[best_model_index_eq_fp]\n",
        "\n",
        "# Evaluamos el modelo seleccionado para el ajuste de equidad en falsos positivos\n",
        "predictions_eq_fp = best_model_eq_fp.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeV4ncoOCguV",
        "outputId": "f7f0b876-3d08-4db5-e7e6-3974d0c50a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043867 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.637110 -> initscore=0.562842\n",
            "[LightGBM] [Info] Start training from score 0.562842\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.649939 -> initscore=0.618772\n",
            "[LightGBM] [Info] Start training from score 0.618772\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.641386 -> initscore=0.581383\n",
            "[LightGBM] [Info] Start training from score 0.581383\n",
            "[LightGBM] [Info] Number of positive: 349384, number of negative: 450616\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.600052 -> initscore=0.405682\n",
            "[LightGBM] [Info] Start training from score 0.405682\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022951 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660487 -> initscore=0.665464\n",
            "[LightGBM] [Info] Start training from score 0.665464\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023225 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654215 -> initscore=0.637618\n",
            "[LightGBM] [Info] Start training from score 0.637618\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042572 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.645661 -> initscore=0.600022\n",
            "[LightGBM] [Info] Start training from score 0.600022\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023370 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.637108 -> initscore=0.562832\n",
            "[LightGBM] [Info] Start training from score 0.562832\n",
            "[LightGBM] [Info] Number of positive: 349384, number of negative: 450616\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040901 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.577265 -> initscore=0.311554\n",
            "[LightGBM] [Info] Start training from score 0.311554\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040231 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.587179 -> initscore=0.352316\n",
            "[LightGBM] [Info] Start training from score 0.352316\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023470 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624180 -> initscore=0.507327\n",
            "[LightGBM] [Info] Start training from score 0.507327\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023656 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.658490 -> initscore=0.656575\n",
            "[LightGBM] [Info] Start training from score 0.656575\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039298 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.649937 -> initscore=0.618762\n",
            "[LightGBM] [Info] Start training from score 0.618762\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023019 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.641383 -> initscore=0.581373\n",
            "[LightGBM] [Info] Start training from score 0.581373\n",
            "[LightGBM] [Info] Number of positive: 349384, number of negative: 450616\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043636 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.599729 -> initscore=0.404336\n",
            "[LightGBM] [Info] Start training from score 0.404336\n",
            "[LightGBM] [Info] Number of positive: 348931, number of negative: 451069\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562138 -> initscore=0.249844\n",
            "[LightGBM] [Info] Start training from score 0.249844\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562513 -> initscore=0.251366\n",
            "[LightGBM] [Info] Start training from score 0.251366\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.576699 -> initscore=0.309237\n",
            "[LightGBM] [Info] Start training from score 0.309237\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.602211 -> initscore=0.414684\n",
            "[LightGBM] [Info] Start training from score 0.414684\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023525 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.661617 -> initscore=0.670509\n",
            "[LightGBM] [Info] Start training from score 0.670509\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023322 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023324 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.645659 -> initscore=0.600011\n",
            "[LightGBM] [Info] Start training from score 0.600011\n",
            "[LightGBM] [Info] Number of positive: 168687, number of negative: 631313\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040343 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.637105 -> initscore=0.562822\n",
            "[LightGBM] [Info] Start training from score 0.562822\n",
            "[LightGBM] [Info] Number of positive: 349233, number of negative: 450767\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022902 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.577021 -> initscore=0.310558\n",
            "[LightGBM] [Info] Start training from score 0.310558\n",
            "[LightGBM] [Info] Number of positive: 349233, number of negative: 450767\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023497 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.551323 -> initscore=0.206020\n",
            "[LightGBM] [Info] Start training from score 0.206020\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023270 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.568811 -> initscore=0.277003\n",
            "[LightGBM] [Info] Start training from score 0.277003\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.587487 -> initscore=0.353585\n",
            "[LightGBM] [Info] Start training from score 0.353585\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040290 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624838 -> initscore=0.510133\n",
            "[LightGBM] [Info] Start training from score 0.510133\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025491 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.658488 -> initscore=0.656564\n",
            "[LightGBM] [Info] Start training from score 0.656564\n",
            "[LightGBM] [Info] Number of positive: 522917, number of negative: 277083\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076268 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.649935 -> initscore=0.618751\n",
            "[LightGBM] [Info] Start training from score 0.618751\n",
            "[LightGBM] [Info] Number of positive: 523219, number of negative: 276781\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023846 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.641248 -> initscore=0.580783\n",
            "[LightGBM] [Info] Start training from score 0.580783\n",
            "[LightGBM] [Info] Number of positive: 349233, number of negative: 450767\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023010 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.599268 -> initscore=0.402415\n",
            "[LightGBM] [Info] Start training from score 0.402415\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043444 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.576931 -> initscore=0.310189\n",
            "[LightGBM] [Info] Start training from score 0.310189\n",
            "[LightGBM] [Info] Number of positive: 450767, number of negative: 349233\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.602644 -> initscore=0.416496\n",
            "[LightGBM] [Info] Start training from score 0.416496\n",
            "[LightGBM] [Info] Number of positive: 354230, number of negative: 445770\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025702 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.662764 -> initscore=0.675635\n",
            "[LightGBM] [Info] Start training from score 0.675635\n",
            "[LightGBM] [Info] Number of positive: 523219, number of negative: 276781\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023030 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654065 -> initscore=0.636955\n",
            "[LightGBM] [Info] Start training from score 0.636955\n",
            "[LightGBM] [Info] Number of positive: 523219, number of negative: 276781\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044678 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.645382 -> initscore=0.598802\n",
            "[LightGBM] [Info] Start training from score 0.598802\n",
            "[LightGBM] [Info] Number of positive: 450314, number of negative: 349686\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023001 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.587797 -> initscore=0.354864\n",
            "[LightGBM] [Info] Start training from score 0.354864\n",
            "[LightGBM] [Info] Number of positive: 450616, number of negative: 349384\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022802 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625414 -> initscore=0.512591\n",
            "[LightGBM] [Info] Start training from score 0.512591\n",
            "[LightGBM] [Info] Number of positive: 523219, number of negative: 276781\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038944 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.658187 -> initscore=0.655226\n",
            "[LightGBM] [Info] Start training from score 0.655226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calcular la precisi√≥n para el modelo con equidad en falsos positivos\n",
        "accuracy_eq_fp = accuracy_score(y_test, predictions_eq_fp)\n",
        "print(f\"Accuracy (with fairness constraint on false positives): {accuracy_eq_fp}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNSnfxPSGlHs",
        "outputId": "23973385-6b73-4f10-cc67-f606a6a56ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (with fairness constraint on false positives): 0.80694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.metrics import MetricFrame\n",
        "\n",
        "# Calcular la precisi√≥n por grupo de sexo y raza para el modelo con equidad en falsos positivos\n",
        "sensitive_features_test = X_test[['applicant_sex']]  # Puedes modificar esto seg√∫n las caracter√≠sticas sensibles de inter√©s\n",
        "metrics_eq_fp = MetricFrame(metrics={'precision': precision_score, 'recall': recall_score},\n",
        "                            y_true=y_test,\n",
        "                            y_pred=predictions_eq_fp,  # Aqu√≠ pasas las predicciones del modelo con equidad en falsos positivos\n",
        "                            sensitive_features=sensitive_features_test)\n",
        "\n",
        "# Obtener los valores de las m√©tricas por grupo\n",
        "group_metrics_eq_fp = metrics_eq_fp.by_group\n",
        "\n",
        "# Imprimir las m√©tricas por grupo de una manera controlada\n",
        "print(\"Precision and recall by applicant_sex:\")\n",
        "for group, metrics in group_metrics_eq_fp.iterrows():\n",
        "    print(f\"Applicant_sex: {group}\")\n",
        "    print(f\"Precision: {metrics['precision']}\")\n",
        "    print(f\"Recall: {metrics['recall']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46HzH2tIG8sM",
        "outputId": "699adcf0-5d8b-41e5-cbfa-1ecffaf427ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision and recall by applicant_sex:\n",
            "Applicant_sex: 0\n",
            "Precision: 0.8445501257242812\n",
            "Recall: 0.8713173922851343\n",
            "\n",
            "Applicant_sex: 1\n",
            "Precision: 0.8332497034942067\n",
            "Recall: 0.8662240663900415\n",
            "\n",
            "Applicant_sex: 2\n",
            "Precision: 0.819672131147541\n",
            "Recall: 0.9174311926605505\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Para EDAD\n",
        "# Creamos un nuevo modelo LGBMClassifier para el ajuste de equidad en falsos positivos\n",
        "lgbm_model_eq_fp = LGBMClassifier()\n",
        "\n",
        "# Creamos un nuevo pipeline con el modelo LGBM y el escalador para el ajuste de equidad en falsos positivos\n",
        "pipeline_eq_fp = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lgbm', lgbm_model_eq_fp)\n",
        "])\n",
        "\n",
        "# Creamos el mitigador de sesgo para el ajuste de equidad en falsos positivos\n",
        "sweep_eq_fp_1 = GridSearch(\n",
        "    pipeline_eq_fp,\n",
        "    constraints=ErrorRateParity(),\n",
        "    grid_size=40,\n",
        "    sample_weight_name='lgbm__sample_weight'\n",
        ")\n",
        "\n",
        "# Entrenamos el mitigador de sesgo para el ajuste de equidad en falsos positivos\n",
        "sweep_eq_fp_1.fit(X_train, y_train, sensitive_features=X_train[['applicant_age']])\n",
        "\n",
        "# Seleccionamos el mejor modelo seg√∫n la m√©trica de equidad en falsos positivos\n",
        "sweep_preds_eq_fp_1 = [predictor.predict(X_test) for predictor in sweep_eq_fp_1.predictors_]\n",
        "sweep_scores_eq_fp_1 = [accuracy_score(y_test, preds) for preds in sweep_preds_eq_fp_1]\n",
        "best_model_index_eq_fp_1 = np.argmax(sweep_scores_eq_fp_1)\n",
        "best_model_eq_fp_1 = sweep_eq_fp_1.predictors_[best_model_index_eq_fp_1]\n",
        "\n",
        "# Evaluamos el modelo seleccionado para el ajuste de equidad en falsos positivos\n",
        "predictions_eq_fp_1 = best_model_eq_fp_1.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SS9V6beICDS",
        "outputId": "f34c755b-ea59-4ac6-bfcd-64abfddfd9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fairlearn.reductions._grid_search._grid_generator:The grid has 7 dimensions. It is not recommended to use more than 4, otherwise a prohibitively large grid size is required to explore the space thoroughly. For such cases consider using ExponentiatedGradient from the fairlearn.reductions module.\n",
            "WARNING:fairlearn.reductions._grid_search._grid_generator:Generating a grid with 40 grid points. It is recommended to use at least 128 grid points. Please consider increasing grid_size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.531840 -> initscore=0.127534\n",
            "[LightGBM] [Info] Start training from score 0.127534\n",
            "[LightGBM] [Info] Number of positive: 391325, number of negative: 408675\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022977 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.529395 -> initscore=0.117717\n",
            "[LightGBM] [Info] Start training from score 0.117717\n",
            "[LightGBM] [Info] Number of positive: 456059, number of negative: 343941\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574013 -> initscore=0.298243\n",
            "[LightGBM] [Info] Start training from score 0.298243\n",
            "[LightGBM] [Info] Number of positive: 410066, number of negative: 389934\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.565770 -> initscore=0.264613\n",
            "[LightGBM] [Info] Start training from score 0.264613\n",
            "[LightGBM] [Info] Number of positive: 425100, number of negative: 374900\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024499 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.567073 -> initscore=0.269917\n",
            "[LightGBM] [Info] Start training from score 0.269917\n",
            "[LightGBM] [Info] Number of positive: 441458, number of negative: 358542\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562900 -> initscore=0.252941\n",
            "[LightGBM] [Info] Start training from score 0.252941\n",
            "[LightGBM] [Info] Number of positive: 449464, number of negative: 350536\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024330 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.528439 -> initscore=0.113880\n",
            "[LightGBM] [Info] Start training from score 0.113880\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.565045 -> initscore=0.261661\n",
            "[LightGBM] [Info] Start training from score 0.261661\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.567674 -> initscore=0.272369\n",
            "[LightGBM] [Info] Start training from score 0.272369\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023367 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532270 -> initscore=0.129258\n",
            "[LightGBM] [Info] Start training from score 0.129258\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023614 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538803 -> initscore=0.155524\n",
            "[LightGBM] [Info] Start training from score 0.155524\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040359 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546720 -> initscore=0.187427\n",
            "[LightGBM] [Info] Start training from score 0.187427\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023036 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507531 -> initscore=0.030128\n",
            "[LightGBM] [Info] Start training from score 0.030128\n",
            "[LightGBM] [Info] Number of positive: 458395, number of negative: 341605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022713 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.577805 -> initscore=0.313770\n",
            "[LightGBM] [Info] Start training from score 0.313770\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024140 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507510 -> initscore=0.030043\n",
            "[LightGBM] [Info] Start training from score 0.030043\n",
            "[LightGBM] [Info] Number of positive: 453964, number of negative: 346036\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024235 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557222 -> initscore=0.229897\n",
            "[LightGBM] [Info] Start training from score 0.229897\n",
            "[LightGBM] [Info] Number of positive: 407971, number of negative: 392029\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039190 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.542549 -> initscore=0.170609\n",
            "[LightGBM] [Info] Start training from score 0.170609\n",
            "[LightGBM] [Info] Number of positive: 423005, number of negative: 376995\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039600 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.545863 -> initscore=0.183970\n",
            "[LightGBM] [Info] Start training from score 0.183970\n",
            "[LightGBM] [Info] Number of positive: 439363, number of negative: 360637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023846 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544852 -> initscore=0.179890\n",
            "[LightGBM] [Info] Start training from score 0.179890\n",
            "[LightGBM] [Info] Number of positive: 447369, number of negative: 352631\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.514871 -> initscore=0.059501\n",
            "[LightGBM] [Info] Start training from score 0.059501\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.541100 -> initscore=0.164772\n",
            "[LightGBM] [Info] Start training from score 0.164772\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022925 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.549187 -> initscore=0.197386\n",
            "[LightGBM] [Info] Start training from score 0.197386\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.514869 -> initscore=0.059493\n",
            "[LightGBM] [Info] Start training from score 0.059493\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042499 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521202 -> initscore=0.084857\n",
            "[LightGBM] [Info] Start training from score 0.084857\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.528876 -> initscore=0.115632\n",
            "[LightGBM] [Info] Start training from score 0.115632\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022927 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.490890 -> initscore=-0.036444\n",
            "[LightGBM] [Info] Start training from score -0.036444\n",
            "[LightGBM] [Info] Number of positive: 521034, number of negative: 278966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023147 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.580610 -> initscore=0.325277\n",
            "[LightGBM] [Info] Start training from score 0.325277\n",
            "[LightGBM] [Info] Number of positive: 472705, number of negative: 327295\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023191 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582479 -> initscore=0.332958\n",
            "[LightGBM] [Info] Start training from score 0.332958\n",
            "[LightGBM] [Info] Number of positive: 487739, number of negative: 312261\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039775 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582225 -> initscore=0.331916\n",
            "[LightGBM] [Info] Start training from score 0.331916\n",
            "[LightGBM] [Info] Number of positive: 504097, number of negative: 295903\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.577658 -> initscore=0.313165\n",
            "[LightGBM] [Info] Start training from score 0.313165\n",
            "[LightGBM] [Info] Number of positive: 512103, number of negative: 287897\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023046 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550555 -> initscore=0.202911\n",
            "[LightGBM] [Info] Start training from score 0.202911\n",
            "[LightGBM] [Info] Number of positive: 521034, number of negative: 278966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023194 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.594586 -> initscore=0.382956\n",
            "[LightGBM] [Info] Start training from score 0.382956\n",
            "[LightGBM] [Info] Number of positive: 521034, number of negative: 278966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022838 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.604814 -> initscore=0.425565\n",
            "[LightGBM] [Info] Start training from score 0.425565\n",
            "[LightGBM] [Info] Number of positive: 521034, number of negative: 278966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024278 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574150 -> initscore=0.298804\n",
            "[LightGBM] [Info] Start training from score 0.298804\n",
            "[LightGBM] [Info] Number of positive: 521034, number of negative: 278966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.579809 -> initscore=0.321987\n",
            "[LightGBM] [Info] Start training from score 0.321987\n",
            "[LightGBM] [Info] Number of positive: 521034, number of negative: 278966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041911 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.586666 -> initscore=0.350199\n",
            "[LightGBM] [Info] Start training from score 0.350199\n",
            "[LightGBM] [Info] Number of positive: 475041, number of negative: 324959\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027529 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550522 -> initscore=0.202782\n",
            "[LightGBM] [Info] Start training from score 0.202782\n",
            "[LightGBM] [Info] Number of positive: 441746, number of negative: 358254\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023214 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.578449 -> initscore=0.316409\n",
            "[LightGBM] [Info] Start training from score 0.316409\n",
            "[LightGBM] [Info] Number of positive: 458104, number of negative: 341896\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023588 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.572793 -> initscore=0.293256\n",
            "[LightGBM] [Info] Start training from score 0.293256\n",
            "[LightGBM] [Info] Number of positive: 466110, number of negative: 333890\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023172 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537931 -> initscore=0.152016\n",
            "[LightGBM] [Info] Start training from score 0.152016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calcular la precisi√≥n para el modelo con equidad en falsos positivos\n",
        "accuracy_eq_fp = accuracy_score(y_test, predictions_eq_fp_1)\n",
        "print(f\"Accuracy (with fairness constraint on false positives): {accuracy_eq_fp}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fk23wi9LxMl",
        "outputId": "ec568319-a5a3-4e7b-f549-32e4fb1fe9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (with fairness constraint on false positives): 0.782865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calcular el F1 Score del modelo ajustado para el ajuste de equidad en falsos positivos\n",
        "f1_score_eq_fp_1 = f1_score(y_test, predictions_eq_fp_1)\n",
        "\n",
        "# Imprimir el F1 Score\n",
        "print(\"F1 Score Model with Error Rate Parity Constraint on False Positives:\", f1_score_eq_fp_1)\n"
      ],
      "metadata": {
        "id": "U4WLzusGbz4Q",
        "outputId": "0d70438a-52f5-4f0d-c2bb-0ff042ec71a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score Model with Error Rate Parity Constraint on False Positives: 0.8362030272284604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calcular la precisi√≥n para el modelo con equidad en falsos positivos\n",
        "accuracy_eq_fp = accuracy_score(y_test, predictions_eq_fp_1)\n",
        "precision_eq_fp = precision_score(y_test, predictions_eq_fp_1, average='weighted')\n",
        "recall_eq_fp = recall_score(y_test, predictions_eq_fp_1, average='weighted')\n",
        "f1_eq_fp = f1_score(y_test, predictions_eq_fp_1, average='weighted')\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(f\"Accuracy (with fairness constraint on false positives): {accuracy_eq_fp:.4f}\")\n",
        "print(f\"Precision (with fairness constraint on false positives): {precision_eq_fp:.4f}\")\n",
        "print(f\"Recall (with fairness constraint on false positives): {recall_eq_fp:.4f}\")\n",
        "print(f\"F1 Score (with fairness constraint on false positives): {f1_eq_fp:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjaWD6_TCRYA",
        "outputId": "9dcbedb6-29ad-4e83-afaf-5731f227ae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (with fairness constraint on false positives): 0.7829\n",
            "Precision (with fairness constraint on false positives): 0.7807\n",
            "Recall (with fairness constraint on false positives): 0.7829\n",
            "F1 Score (with fairness constraint on false positives): 0.7816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import GridSearch, TruePositiveRateParity\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "XP6kaz9sInt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo modelo LGBMClassifier para el ajuste de equidad en verdaderos positivos\n",
        "lgbm_model_eq_fn = LGBMClassifier()\n",
        "\n",
        "# Crear un nuevo pipeline con el modelo LGBM y el escalador para el ajuste de equidad en verdaderos positivos\n",
        "pipeline_eq_fn = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lgbm', lgbm_model_eq_fn)\n",
        "])\n",
        "\n",
        "# Crear el mitigador de sesgo para el ajuste de equidad en verdaderos positivos\n",
        "sweep_eq_fn_1 = GridSearch(\n",
        "    pipeline_eq_fn,\n",
        "    constraints=TruePositiveRateParity(),\n",
        "    grid_size=40,\n",
        "    sample_weight_name='lgbm__sample_weight'\n",
        ")\n",
        "\n",
        "# Entrenar el mitigador de sesgo para el ajuste de equidad en verdaderos positivos\n",
        "sweep_eq_fn_1.fit(X_train, y_train, sensitive_features=X_train[['applicant_age']])\n",
        "\n",
        "# Seleccionar el mejor modelo seg√∫n la m√©trica de equidad en verdaderos positivos\n",
        "sweep_preds_eq_fn_1 = [predictor.predict(X_test) for predictor in sweep_eq_fn_1.predictors_]\n",
        "sweep_scores_eq_fn_1 = [accuracy_score(y_test, preds) for preds in sweep_preds_eq_fn_1]\n",
        "best_model_index_eq_fn_1 = np.argmax(sweep_scores_eq_fn_1)\n",
        "best_model_eq_fn_1 = sweep_eq_fn_1.predictors_[best_model_index_eq_fn_1]\n",
        "\n",
        "# Evaluar el modelo seleccionado para el ajuste de equidad en verdaderos positivos\n",
        "predictions_eq_fn_1 = best_model_eq_fn_1.predict(X_test)\n",
        "\n",
        "# Calcular m√©tricas adicionales\n",
        "accuracy_eq_fn = accuracy_score(y_test, predictions_eq_fn_1)\n",
        "precision_eq_fn = precision_score(y_test, predictions_eq_fn_1, average='weighted')\n",
        "recall_eq_fn = recall_score(y_test, predictions_eq_fn_1, average='weighted')\n",
        "f1_eq_fn = f1_score(y_test, predictions_eq_fn_1, average='weighted')\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f\"Accuracy (with fairness constraint on false negatives): {accuracy_eq_fn}\")\n",
        "print(f\"Precision (with fairness constraint on false negatives): {precision_eq_fn}\")\n",
        "print(f\"Recall (with fairness constraint on false negatives): {recall_eq_fn}\")\n",
        "print(f\"F1 Score (with fairness constraint on false negatives): {f1_eq_fn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMdXW1C9Hoea",
        "outputId": "446e172e-2ea2-48e4-ce22-4754eb0b7606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fairlearn.reductions._grid_search._grid_generator:The grid has 7 dimensions. It is not recommended to use more than 4, otherwise a prohibitively large grid size is required to explore the space thoroughly. For such cases consider using ExponentiatedGradient from the fairlearn.reductions module.\n",
            "WARNING:fairlearn.reductions._grid_search._grid_generator:Generating a grid with 40 grid points. It is recommended to use at least 128 grid points. Please consider increasing grid_size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 125837, number of negative: 674163\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040055 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550654 -> initscore=0.203314\n",
            "[LightGBM] [Info] Start training from score 0.203314\n",
            "[LightGBM] [Info] Number of positive: 236678, number of negative: 563322\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562323 -> initscore=0.250597\n",
            "[LightGBM] [Info] Start training from score 0.250597\n",
            "[LightGBM] [Info] Number of positive: 142027, number of negative: 657973\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023831 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552078 -> initscore=0.209072\n",
            "[LightGBM] [Info] Start training from score 0.209072\n",
            "[LightGBM] [Info] Number of positive: 237458, number of negative: 562542\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562425 -> initscore=0.251008\n",
            "[LightGBM] [Info] Start training from score 0.251008\n",
            "[LightGBM] [Info] Number of positive: 212968, number of negative: 587032\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024399 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.559396 -> initscore=0.238713\n",
            "[LightGBM] [Info] Start training from score 0.238713\n",
            "[LightGBM] [Info] Number of positive: 176004, number of negative: 623996\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555344 -> initscore=0.222288\n",
            "[LightGBM] [Info] Start training from score 0.222288\n",
            "[LightGBM] [Info] Number of positive: 141978, number of negative: 658022\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023826 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552074 -> initscore=0.209054\n",
            "[LightGBM] [Info] Start training from score 0.209054\n",
            "[LightGBM] [Info] Number of positive: 125837, number of negative: 674163\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023006 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.601103 -> initscore=0.410065\n",
            "[LightGBM] [Info] Start training from score 0.410065\n",
            "[LightGBM] [Info] Number of positive: 507229, number of negative: 292771\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022942 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552105 -> initscore=0.209179\n",
            "[LightGBM] [Info] Start training from score 0.209179\n",
            "[LightGBM] [Info] Number of positive: 473203, number of negative: 326797\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022970 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553647 -> initscore=0.215417\n",
            "[LightGBM] [Info] Start training from score 0.215417\n",
            "[LightGBM] [Info] Number of positive: 436239, number of negative: 363761\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022806 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555429 -> initscore=0.222630\n",
            "[LightGBM] [Info] Start training from score 0.222630\n",
            "[LightGBM] [Info] Number of positive: 411749, number of negative: 388251\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039578 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.556676 -> initscore=0.227683\n",
            "[LightGBM] [Info] Start training from score 0.227683\n",
            "[LightGBM] [Info] Number of positive: 507180, number of negative: 292820\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023064 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552107 -> initscore=0.209188\n",
            "[LightGBM] [Info] Start training from score 0.209188\n",
            "[LightGBM] [Info] Number of positive: 412529, number of negative: 387471\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042684 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.556635 -> initscore=0.227518\n",
            "[LightGBM] [Info] Start training from score 0.227518\n",
            "[LightGBM] [Info] Number of positive: 110841, number of negative: 689159\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025566 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.549403 -> initscore=0.198257\n",
            "[LightGBM] [Info] Start training from score 0.198257\n",
            "[LightGBM] [Info] Number of positive: 127031, number of negative: 672969\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038945 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550756 -> initscore=0.203728\n",
            "[LightGBM] [Info] Start training from score 0.203728\n",
            "[LightGBM] [Info] Number of positive: 222462, number of negative: 577538\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042271 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.560535 -> initscore=0.243333\n",
            "[LightGBM] [Info] Start training from score 0.243333\n",
            "[LightGBM] [Info] Number of positive: 197972, number of negative: 602028\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044128 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557683 -> initscore=0.231764\n",
            "[LightGBM] [Info] Start training from score 0.231764\n",
            "[LightGBM] [Info] Number of positive: 161008, number of negative: 638992\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078180 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553854 -> initscore=0.216254\n",
            "[LightGBM] [Info] Start training from score 0.216254\n",
            "[LightGBM] [Info] Number of positive: 126982, number of negative: 673018\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022824 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550752 -> initscore=0.203711\n",
            "[LightGBM] [Info] Start training from score 0.203711\n",
            "[LightGBM] [Info] Number of positive: 110841, number of negative: 689159\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.599807 -> initscore=0.404660\n",
            "[LightGBM] [Info] Start training from score 0.404660\n",
            "[LightGBM] [Info] Number of positive: 507229, number of negative: 292771\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552105 -> initscore=0.209179\n",
            "[LightGBM] [Info] Start training from score 0.209179\n",
            "[LightGBM] [Info] Number of positive: 473203, number of negative: 326797\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023039 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553647 -> initscore=0.215417\n",
            "[LightGBM] [Info] Start training from score 0.215417\n",
            "[LightGBM] [Info] Number of positive: 436239, number of negative: 363761\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022974 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555429 -> initscore=0.222630\n",
            "[LightGBM] [Info] Start training from score 0.222630\n",
            "[LightGBM] [Info] Number of positive: 411749, number of negative: 388251\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023279 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.556676 -> initscore=0.227683\n",
            "[LightGBM] [Info] Start training from score 0.227683\n",
            "[LightGBM] [Info] Number of positive: 507180, number of negative: 292820\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022734 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552107 -> initscore=0.209188\n",
            "[LightGBM] [Info] Start training from score 0.209188\n",
            "[LightGBM] [Info] Number of positive: 16190, number of negative: 783810\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039722 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.542738 -> initscore=0.171371\n",
            "[LightGBM] [Info] Start training from score 0.171371\n",
            "[LightGBM] [Info] Number of positive: 127811, number of negative: 672189\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023209 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550824 -> initscore=0.203999\n",
            "[LightGBM] [Info] Start training from score 0.203999\n",
            "[LightGBM] [Info] Number of positive: 103321, number of negative: 696679\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022951 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548798 -> initscore=0.195816\n",
            "[LightGBM] [Info] Start training from score 0.195816\n",
            "[LightGBM] [Info] Number of positive: 66357, number of negative: 733643\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546029 -> initscore=0.184640\n",
            "[LightGBM] [Info] Start training from score 0.184640\n",
            "[LightGBM] [Info] Number of positive: 32331, number of negative: 767669\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022781 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.543744 -> initscore=0.175426\n",
            "[LightGBM] [Info] Start training from score 0.175426\n",
            "[LightGBM] [Info] Number of positive: 16190, number of negative: 783810\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023025 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.592333 -> initscore=0.373617\n",
            "[LightGBM] [Info] Start training from score 0.373617\n",
            "[LightGBM] [Info] Number of positive: 507229, number of negative: 292771\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552105 -> initscore=0.209180\n",
            "[LightGBM] [Info] Start training from score 0.209180\n",
            "[LightGBM] [Info] Number of positive: 473203, number of negative: 326797\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023531 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553647 -> initscore=0.215417\n",
            "[LightGBM] [Info] Start training from score 0.215417\n",
            "[LightGBM] [Info] Number of positive: 436239, number of negative: 363761\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039188 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555429 -> initscore=0.222630\n",
            "[LightGBM] [Info] Start training from score 0.222630\n",
            "[LightGBM] [Info] Number of positive: 411749, number of negative: 388251\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022996 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.556676 -> initscore=0.227683\n",
            "[LightGBM] [Info] Start training from score 0.227683\n",
            "[LightGBM] [Info] Number of positive: 111621, number of negative: 688379\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040930 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.549466 -> initscore=0.198514\n",
            "[LightGBM] [Info] Start training from score 0.198514\n",
            "[LightGBM] [Info] Number of positive: 198752, number of negative: 601248\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022946 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557770 -> initscore=0.232115\n",
            "[LightGBM] [Info] Start training from score 0.232115\n",
            "[LightGBM] [Info] Number of positive: 161788, number of negative: 638212\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023243 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553929 -> initscore=0.216559\n",
            "[LightGBM] [Info] Start training from score 0.216559\n",
            "[LightGBM] [Info] Number of positive: 127762, number of negative: 672238\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550819 -> initscore=0.203982\n",
            "[LightGBM] [Info] Start training from score 0.203982\n",
            "Accuracy (with fairness constraint on false negatives): 0.782715\n",
            "Precision (with fairness constraint on false negatives): 0.7808650058133211\n",
            "Recall (with fairness constraint on false negatives): 0.782715\n",
            "F1 Score (with fairness constraint on false negatives): 0.781633080467467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular m√©tricas adicionales\n",
        "accuracy_eq_fn = accuracy_score(y_test, predictions_eq_fn_1)\n",
        "precision_eq_fn = precision_score(y_test, predictions_eq_fn_1, average='weighted')\n",
        "recall_eq_fn = recall_score(y_test, predictions_eq_fn_1, average='weighted')\n",
        "f1_eq_fn = f1_score(y_test, predictions_eq_fn_1, average='weighted')\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f\"Accuracy (with fairness constraint on false negatives): {accuracy_eq_fn}\")\n",
        "print(f\"Precision (with fairness constraint on false negatives): {precision_eq_fn}\")\n",
        "print(f\"Recall (with fairness constraint on false negatives): {recall_eq_fn}\")\n",
        "print(f\"F1 Score (with fairness constraint on false negatives): {f1_eq_fn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiIYXda9MWm_",
        "outputId": "3c7b493a-3eb3-4e9b-921e-3d8499c185cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (with fairness constraint on false negatives): 0.782715\n",
            "Precision (with fairness constraint on false negatives): 0.7808650058133211\n",
            "Recall (with fairness constraint on false negatives): 0.782715\n",
            "F1 Score (with fairness constraint on false negatives): 0.781633080467467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fairlearn: Exponentiated Gradient"
      ],
      "metadata": {
        "id": "d5sijsJ_Bhvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import ExponentiatedGradient\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import MetricFrame\n",
        "\n",
        "# Modifica el nombre del par√°metro de peso de muestra en tu modelo LightGBM\n",
        "lgbm_model = LGBMClassifier()\n",
        "lgbm_model.sample_weight = 'lgbm__sample_weight'\n",
        "\n",
        "# Crear el mitigador de sesgo para el modelo que ya tenemos\n",
        "expgrad = ExponentiatedGradient(\n",
        "    lgbm_model,  # Utiliza tu modelo LightGBM ya entrenado\n",
        "    constraints=DemographicParity(),  # Puedes cambiar la m√©trica de equidad si lo deseas\n",
        "    max_iter=5  # Especifica el n√∫mero m√°ximo de iteraciones\n",
        ")\n",
        "\n",
        "# Entrenar el mitigador de sesgo\n",
        "expgrad.fit(X_train, y_train, sensitive_features=X_train[['applicant_sex']])  # Aseg√∫rate de proporcionar las caracter√≠sticas sensibles correctas\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t9EupOK4sioJ",
        "outputId": "b055718e-5a6f-4e16-eb32-bcf1798e632d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058767 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079980 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052317 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654263 -> initscore=0.637833\n",
            "[LightGBM] [Info] Start training from score 0.637833\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079405 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654238 -> initscore=0.637720\n",
            "[LightGBM] [Info] Start training from score 0.637720\n",
            "[LightGBM] [Info] Number of positive: 264771, number of negative: 535229\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501154 -> initscore=0.004614\n",
            "[LightGBM] [Info] Start training from score 0.004614\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053347 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654314 -> initscore=0.638058\n",
            "[LightGBM] [Info] Start training from score 0.638058\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081547 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654263 -> initscore=0.637833\n",
            "[LightGBM] [Info] Start training from score 0.637833\n",
            "[LightGBM] [Info] Number of positive: 619454, number of negative: 180546\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052935 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653534 -> initscore=0.634612\n",
            "[LightGBM] [Info] Start training from score 0.634612\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654365 -> initscore=0.638283\n",
            "[LightGBM] [Info] Start training from score 0.638283\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061178 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654289 -> initscore=0.637945\n",
            "[LightGBM] [Info] Start training from score 0.637945\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056978 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654365 -> initscore=0.638283\n",
            "[LightGBM] [Info] Start training from score 0.638283\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654595 -> initscore=0.639299\n",
            "[LightGBM] [Info] Start training from score 0.639299\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054473 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654979 -> initscore=0.641000\n",
            "[LightGBM] [Info] Start training from score 0.641000\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052721 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654339 -> initscore=0.638166\n",
            "[LightGBM] [Info] Start training from score 0.638166\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052355 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654465 -> initscore=0.638726\n",
            "[LightGBM] [Info] Start training from score 0.638726\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054466 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654846 -> initscore=0.640411\n",
            "[LightGBM] [Info] Start training from score 0.640411\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052339 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655485 -> initscore=0.643239\n",
            "[LightGBM] [Info] Start training from score 0.643239\n",
            "[LightGBM] [Info] Number of positive: 523672, number of negative: 276328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053632 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654247 -> initscore=0.637761\n",
            "[LightGBM] [Info] Start training from score 0.637761\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053210 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654311 -> initscore=0.638041\n",
            "[LightGBM] [Info] Start training from score 0.638041\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654409 -> initscore=0.638475\n",
            "[LightGBM] [Info] Start training from score 0.638475\n",
            "[LightGBM] [Info] Number of positive: 523672, number of negative: 276328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058740 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654569 -> initscore=0.639183\n",
            "[LightGBM] [Info] Start training from score 0.639183\n",
            "[LightGBM] [Info] Number of positive: 523672, number of negative: 276328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654809 -> initscore=0.640247\n",
            "[LightGBM] [Info] Start training from score 0.640247\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060146 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654284 -> initscore=0.637925\n",
            "[LightGBM] [Info] Start training from score 0.637925\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052576 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654356 -> initscore=0.638243\n",
            "[LightGBM] [Info] Start training from score 0.638243\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052409 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654572 -> initscore=0.639197\n",
            "[LightGBM] [Info] Start training from score 0.639197\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654933 -> initscore=0.640795\n",
            "[LightGBM] [Info] Start training from score 0.640795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExponentiatedGradient(constraints=<fairlearn.reductions._moments.utility_parity.DemographicParity object at 0x7ae91a4f8a30>,\n",
              "                      estimator=LGBMClassifier(), max_iter=5,\n",
              "                      nu=0.00022083014448839435)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.DemographicParity object at 0x7ae91a4f8a30&gt;,\n",
              "                      estimator=LGBMClassifier(), max_iter=5,\n",
              "                      nu=0.00022083014448839435)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExponentiatedGradient</label><div class=\"sk-toggleable__content\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.DemographicParity object at 0x7ae91a4f8a30&gt;,\n",
              "                      estimator=LGBMClassifier(), max_iter=5,\n",
              "                      nu=0.00022083014448839435)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_expgrad = expgrad.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Ey7Dq5u5vhmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_expgrad = accuracy_score(y_test, predictions_expgrad)\n"
      ],
      "metadata": {
        "id": "WznJ2JJlvk2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Original Model:\", accuracy_lgbm)\n",
        "print(\"Accuracy Model with Exponentiated Gradient:\", accuracy_expgrad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UliUmhR7voMq",
        "outputId": "20770fe4-453f-47a6-89fc-dd0296c11dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Original Model: 0.807315\n",
            "Accuracy Model with Exponentiated Gradient: 0.80727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Para Edad optimizando falsos positivos\n",
        "from fairlearn.reductions import ExponentiatedGradient, ErrorRateParity\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Modificar el nombre del par√°metro de peso de muestra en tu modelo LightGBM\n",
        "lgbm_model_expgrad = LGBMClassifier()\n",
        "lgbm_model_expgrad.sample_weight = 'lgbm__sample_weight'\n",
        "\n",
        "# Crear el mitigador de sesgo para el modelo existente con ExponentiatedGradient\n",
        "expgrad = ExponentiatedGradient(\n",
        "    lgbm_model_expgrad,  # Utiliza tu modelo LightGBM ya entrenado\n",
        "    constraints=ErrorRateParity(),  # Restricci√≥n de igualdad en falsos positivos\n",
        "    max_iter=5  # N√∫mero m√°ximo de iteraciones\n",
        ")\n",
        "\n",
        "# Entrenar el mitigador de sesgo con ExponentiatedGradient\n",
        "expgrad.fit(X_train, y_train, sensitive_features=X_train[['applicant_age']])\n",
        "\n",
        "# Predecir utilizando el modelo ajustado con ExponentiatedGradient\n",
        "predictions_expgrad = expgrad.predict(X_test)\n",
        "\n",
        "# Calcular la precisi√≥n del modelo ajustado con ExponentiatedGradient\n",
        "accuracy_expgrad = accuracy_score(y_test, predictions_expgrad)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Accuracy Original Model:\", accuracy_lgbm)\n",
        "print(\"Accuracy Model with Exponentiated Gradient (with fairness constraint on false positives):\", accuracy_expgrad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I1Ku6adMZZf",
        "outputId": "707a4a39-4105-4962-ec7e-40695c3e32c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052063 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 518503, number of negative: 281497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.640020 -> initscore=0.575453\n",
            "[LightGBM] [Info] Start training from score 0.575453\n",
            "[LightGBM] [Info] Number of positive: 518503, number of negative: 281497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.648058 -> initscore=0.610513\n",
            "[LightGBM] [Info] Start training from score 0.610513\n",
            "[LightGBM] [Info] Number of positive: 278966, number of negative: 521034\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053067 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.441540 -> initscore=-0.234916\n",
            "[LightGBM] [Info] Start training from score -0.234916\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053195 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.688293 -> initscore=0.792150\n",
            "[LightGBM] [Info] Start training from score 0.792150\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052234 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.662843 -> initscore=0.675991\n",
            "[LightGBM] [Info] Start training from score 0.675991\n",
            "[LightGBM] [Info] Number of positive: 456300, number of negative: 343700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051934 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468620 -> initscore=-0.125685\n",
            "[LightGBM] [Info] Start training from score -0.125685\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079987 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.678916 -> initscore=0.748796\n",
            "[LightGBM] [Info] Start training from score 0.748796\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666862 -> initscore=0.694024\n",
            "[LightGBM] [Info] Start training from score 0.694024\n",
            "[LightGBM] [Info] Number of positive: 451433, number of negative: 348567\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052189 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.539748 -> initscore=0.159329\n",
            "[LightGBM] [Info] Start training from score 0.159329\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077710 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669773 -> initscore=0.707160\n",
            "[LightGBM] [Info] Start training from score 0.707160\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052468 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667444 -> initscore=0.696647\n",
            "[LightGBM] [Info] Start training from score 0.696647\n",
            "[LightGBM] [Info] Number of positive: 346036, number of negative: 453964\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066899 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.540476 -> initscore=0.162259\n",
            "[LightGBM] [Info] Start training from score 0.162259\n",
            "Accuracy Original Model: 0.807315\n",
            "Accuracy Model with Exponentiated Gradient (with fairness constraint on false positives): 0.7976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calcular el F1 Score del modelo ajustado con ExponentiatedGradient\n",
        "f1_score_expgrad = f1_score(y_test, predictions_expgrad)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Accuracy Original Model:\", accuracy_lgbm)\n",
        "print(\"Accuracy Model with Exponentiated Gradient (with fairness constraint on false positives):\", accuracy_expgrad)\n",
        "print(\"F1 Score Model with Exponentiated Gradient (with fairness constraint on false positives):\", f1_score_expgrad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdHoXy47bZH9",
        "outputId": "d7d4c80d-fd42-4695-d181-d7eb8e879fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Original Model: 0.807315\n",
            "Accuracy Model with Exponentiated Gradient (with fairness constraint on false positives): 0.7976\n",
            "F1 Score Model with Exponentiated Gradient (with fairness constraint on false positives): 0.8473052085219386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calcular las m√©tricas de desempe√±o para el modelo ajustado con ExponentiatedGradient\n",
        "accuracy_expgrad = accuracy_score(y_test, predictions_expgrad)\n",
        "precision_expgrad = precision_score(y_test, predictions_expgrad, average='weighted')\n",
        "recall_expgrad = recall_score(y_test, predictions_expgrad, average='weighted')\n",
        "f1_score_expgrad = f1_score(y_test, predictions_expgrad, average='weighted')\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Accuracy Original Model:\", accuracy_lgbm)\n",
        "print(\"Accuracy Model with Exponentiated Gradient (with fairness constraint on false positives):\", accuracy_expgrad)\n",
        "print(\"Precision Model with Exponentiated Gradient (with fairness constraint on false positives):\", precision_expgrad)\n",
        "print(\"Recall Model with Exponentiated Gradient (with fairness constraint on false positives):\", recall_expgrad)\n",
        "print(\"F1 Score Model with Exponentiated Gradient (with fairness constraint on false positives):\", f1_score_expgrad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8jNacciC2FL",
        "outputId": "d67a521e-bdb0-48da-a274-5d33c53fde5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Original Model: 0.807315\n",
            "Accuracy Model with Exponentiated Gradient (with fairness constraint on false positives): 0.7976\n",
            "Precision Model with Exponentiated Gradient (with fairness constraint on false positives): 0.7956681691181744\n",
            "Recall Model with Exponentiated Gradient (with fairness constraint on false positives): 0.7976\n",
            "F1 Score Model with Exponentiated Gradient (with fairness constraint on false positives): 0.796414998587011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import MetricFrame\n",
        "\n",
        "# Modifica el nombre del par√°metro de peso de muestra en tu modelo LightGBM\n",
        "lgbm_model = LGBMClassifier()\n",
        "lgbm_model.sample_weight = 'lgbm__sample_weight'\n",
        "\n",
        "# Crear el mitigador de sesgo para el modelo que ya tenemos\n",
        "expgrad = ExponentiatedGradient(\n",
        "    lgbm_model,  # Utiliza tu modelo LightGBM ya entrenado\n",
        "    constraints=EqualizedOdds(),  # Usamos EqualizedOdds como la restricci√≥n\n",
        "    max_iter=5  # Especifica el n√∫mero m√°ximo de iteraciones\n",
        ")\n",
        "\n",
        "# Entrenar el mitigador de sesgo\n",
        "expgrad.fit(X_train, y_train, sensitive_features=X_train[['applicant_age']])  # Aseg√∫rate de proporcionar las caracter√≠sticas sensibles correctas\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zkx6zjGaM_s-",
        "outputId": "1515b226-c853-4478-e2de-16e29b16ff66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055056 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 517928, number of negative: 282072\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054719 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.651596 -> initscore=0.626060\n",
            "[LightGBM] [Info] Start training from score 0.626060\n",
            "[LightGBM] [Info] Number of positive: 517928, number of negative: 282072\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052423 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653931 -> initscore=0.636364\n",
            "[LightGBM] [Info] Start training from score 0.636364\n",
            "[LightGBM] [Info] Number of positive: 281497, number of negative: 518503\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500779 -> initscore=0.003117\n",
            "[LightGBM] [Info] Start training from score 0.003117\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079562 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654213 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 49946, number of negative: 750054\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078443 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500881 -> initscore=0.003524\n",
            "[LightGBM] [Info] Start training from score 0.003524\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053703 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654213 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654213 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 600371, number of negative: 199629\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052361 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.518211 -> initscore=0.072876\n",
            "[LightGBM] [Info] Start training from score 0.072876\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056528 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654212 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 523370, number of negative: 276630\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078633 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654213 -> initscore=0.637608\n",
            "[LightGBM] [Info] Start training from score 0.637608\n",
            "[LightGBM] [Info] Number of positive: 567141, number of negative: 232859\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052632 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 788\n",
            "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.595213 -> initscore=0.385560\n",
            "[LightGBM] [Info] Start training from score 0.385560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExponentiatedGradient(constraints=<fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7ae91d0b2020>,\n",
              "                      estimator=LGBMClassifier(), max_iter=5,\n",
              "                      nu=0.00022083014448839435)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7ae91d0b2020&gt;,\n",
              "                      estimator=LGBMClassifier(), max_iter=5,\n",
              "                      nu=0.00022083014448839435)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExponentiatedGradient</label><div class=\"sk-toggleable__content\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7ae91d0b2020&gt;,\n",
              "                      estimator=LGBMClassifier(), max_iter=5,\n",
              "                      nu=0.00022083014448839435)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Realizar predicciones en el conjunto de datos de prueba\n",
        "y_pred = expgrad.predict(X_test)\n",
        "\n",
        "# Calcular las m√©tricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gN_vK94PX1X",
        "outputId": "c6882e94-be3b-40c6-8212-e3e42ce5e1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.803155\n",
            "Precision: 0.8381422209749722\n",
            "Recall: 0.86672165200391\n",
            "F1 Score: 0.8521923913002669\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}